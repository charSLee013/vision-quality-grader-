import os
import glob
import json
import re
import base64
import time
import filetype
import xmltodict
import traceback
import aiofiles
from dotenv import load_dotenv
from colorama import init, Fore, Style
from PIL import Image
import io
from typing import Optional, Dict

# åˆå§‹åŒ–coloramaç”¨äºå½©è‰²è¾“å‡º
init(autoreset=True)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ç”¨æˆ·å®šä¹‰çš„æç¤ºè¯æ¨¡æ¿
USER_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾ç‰‡è´¨é‡è¯„ä¼°ä¸“å®¶ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
1. **å›¾åƒæ¥æºåˆ†æ**ï¼š
   - **AIç”Ÿæˆæ£€æµ‹**ï¼šæ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨ä»¥ä¸‹ç‰¹å¾ï¼ˆä»»ä¸€å³å¯åˆ¤å®šä¸ºAIç”Ÿæˆï¼‰ï¼š
     - è¿‡åº¦å¹³æ»‘çš„çº¹ç†ï¼ˆå¦‚çš®è‚¤æ— æ¯›å­”ã€æ¤è¢«æ— ç»†èŠ‚ï¼‰ã€‚
     - ä¸è‡ªç„¶çš„å…‰å½±ï¼ˆå¦‚å…‰æºæ–¹å‘çŸ›ç›¾ã€é˜´å½±ä¸ç¬¦åˆç‰©ç†è§„å¾‹ï¼‰ã€‚
     - å¼‚å¸¸å®Œç¾çš„æ„å›¾ï¼ˆå¦‚å®Œå…¨å¯¹ç§°ä¸”æ— æ‹æ‘„æŠ–åŠ¨ç—•è¿¹ï¼‰ã€‚
     - éç°å®å…ƒç´ ï¼ˆå¦‚äººç‰©æ‰‹æŒ‡æ•°é‡å¼‚å¸¸ã€ç‰©ä½“æ¯”ä¾‹å¤±çœŸï¼‰ã€‚
   - **çœŸå®ç…§ç‰‡ç‰¹å¾**ï¼šåˆ¤æ–­æ˜¯å¦ç¬¦åˆçœŸå®æ‹æ‘„æ¡ä»¶ï¼ˆå¦‚å­˜åœ¨å™ªç‚¹ã€è½»å¾®æ¨¡ç³Šã€è‡ªç„¶æ™¯æ·±ï¼‰ã€‚

2. **æ°´å°æ£€æµ‹**ï¼š
   - åˆ†æå…¨å›¾æ˜¯å¦å­˜åœ¨å¯è§æ°´å°ï¼ˆå¦‚å“ç‰ŒLOGOã€ç‰ˆæƒæ–‡å­—ï¼‰ï¼Œæè¿°ä½ç½®å’Œæ˜¾è‘—æ€§ã€‚

3. **è´¨é‡è¯„åˆ†ç»´åº¦**ï¼š
   - **æ¸…æ™°åº¦**ï¼šåˆ†è¾¨ç‡æ˜¯å¦è¶³å¤Ÿï¼Œæ˜¯å¦å­˜åœ¨æ¨¡ç³Šæˆ–å‹ç¼©ä¼ªå½±ã€‚
   - **æ„å›¾**ï¼šç”»é¢å¸ƒå±€æ˜¯å¦ç¾è§‚ï¼Œä¸»ä½“æ˜¯å¦çªå‡ºã€‚
   - **è‰²å½©**ï¼šè‰²è°ƒæ˜¯å¦è‡ªç„¶ï¼Œæ˜¯å¦å­˜åœ¨è¿‡æ›æˆ–æ¬ æ›ã€‚
   - **å†…å®¹ç›¸å…³æ€§**ï¼šå›¾ç‰‡å†…å®¹æ˜¯å¦ç¬¦åˆç°å®é€»è¾‘ï¼ˆå¦‚äººç‰©è¡¨æƒ…è‡ªç„¶ã€åœºæ™¯æ— å¼‚å¸¸ï¼‰ã€‚

4. **ç»¼åˆè¯„åˆ†è§„åˆ™**ï¼š
   - **åŸºç¡€åˆ†**ï¼šæŒ‰æƒé‡è®¡ç®—æ€»åˆ†ï¼ˆæ¸…æ™°åº¦40%ï¼Œæ„å›¾30%ï¼Œè‰²å½©20%ï¼Œå†…å®¹10%ï¼‰ã€‚
   - **AIç”Ÿæˆæƒ©ç½š**ï¼šè‹¥æ£€æµ‹ä¸ºAIç”Ÿæˆï¼Œæ€»åˆ†ç›´æ¥æ‰£é™¤ **2.0åˆ†**ï¼ˆæœ€ä½åˆ†ä¿ç•™0åˆ†ï¼‰ã€‚
   - **æœ€ç»ˆç­‰çº§**ï¼š
     - â‰¥8.5ï¼šé«˜è´¨é‡ï¼ˆçœŸå®ç…§ç‰‡ä¸”æ— æ˜æ˜¾ç¼ºé™·ï¼‰ã€‚
     - 7.0-8.4ï¼šä¸­ç­‰è´¨é‡ï¼ˆçœŸå®ç…§ç‰‡ä½†æœ‰è½»å¾®ç¼ºé™·ï¼‰ã€‚
     - <7.0ï¼šä½è´¨é‡ï¼ˆAIç”Ÿæˆæˆ–ä¸¥é‡ç¼ºé™·ï¼‰ã€‚

5. **è¾“å‡ºè§„èŒƒ**ï¼š
   - é¦–å…ˆç”¨è‡ªç„¶è¯­è¨€è¯¦ç»†åˆ†æå›¾ç‰‡è´¨é‡å„ä¸ªç»´åº¦
   - æœ€åå¿…é¡»è¾“å‡ºçº¯å‡€çš„XMLæ ¼å¼ç»“æœï¼Œä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼ï¼š

<result>
<is_ai_generated>trueæˆ–false</is_ai_generated>
<watermark_present>trueæˆ–false</watermark_present>
<watermark_location>æ°´å°ä½ç½®æè¿°æˆ–æ— </watermark_location>
<score>æ•°å­—å¾—åˆ†</score>
<feedback>ç®€è¦è¯„åˆ†ç†ç”±</feedback>
</result>

é‡è¦ï¼šXMLéƒ¨åˆ†å¿…é¡»æ˜¯çº¯å‡€æ ¼å¼ï¼Œä¸è¦ç”¨markdownä»£ç å—åŒ…è£…ï¼Œä¸è¦æœ‰é¢å¤–çš„æ ¼å¼åŒ–ç¬¦å·ã€‚
"""

def validate_config():
    """éªŒè¯å¿…éœ€çš„ç¯å¢ƒå˜é‡é…ç½®"""
    required_vars = ['VLM_API_ENDPOINT', 'VLM_API_TOKEN', 'VLM_MODEL_NAME']
    missing_vars = []
    
    for var in required_vars:
        if not os.getenv(var):
            missing_vars.append(var)
    
    if missing_vars:
        raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}ã€‚è¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®ã€‚")
    
    # æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆæ©ç æ•æ„Ÿä¿¡æ¯ï¼‰
    token = os.getenv('VLM_API_TOKEN', '')
    masked_token = token[:8] + '*' * (len(token) - 12) + token[-4:] if len(token) > 12 else '***'
    
    print(f"{Fore.GREEN}âœ“ é…ç½®åŠ è½½å®Œæˆ:{Style.RESET_ALL}")
    print(f"  ğŸŒ APIç«¯ç‚¹: {Fore.CYAN}{os.getenv('VLM_API_ENDPOINT')}{Style.RESET_ALL}")
    print(f"  ğŸ”‘ APIä»¤ç‰Œ: {Fore.YELLOW}{masked_token}{Style.RESET_ALL}")
    print(f"  ğŸ¤– æ¨¡å‹åç§°: {Fore.MAGENTA}{os.getenv('VLM_MODEL_NAME')}{Style.RESET_ALL}")
    print(f"  ğŸš€ å¹¶å‘æ•°é‡: {Fore.BLUE}{os.getenv('CONCURRENT_LIMIT', '3')}{Style.RESET_ALL}")
    
    # è¿”å›é…ç½®å­—å…¸
    return {
        'api_base': os.getenv('VLM_API_ENDPOINT'),
        'api_key': os.getenv('VLM_API_TOKEN'),
        'model_name': os.getenv('VLM_MODEL_NAME'),
        'max_tokens': int(os.getenv('VLM_MAX_TOKENS', '16384')),
        'temperature': float(os.getenv('VLM_TEMPERATURE', '0.3')),
        'timeout': int(os.getenv('VLM_TIMEOUT', '180')),
        'concurrent_limit': int(os.getenv('CONCURRENT_LIMIT', '3'))
    }

def find_images(root_dir, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.webp')):
    """é€’å½’æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶"""
    all_images = []
    for ext in extensions:
        all_images.extend(glob.glob(os.path.join(root_dir, '**', f'*{ext}'), recursive=True))
        all_images.extend(glob.glob(os.path.join(root_dir, '**', f'*{ext.upper()}'), recursive=True))
    return sorted(list(set(all_images)))  # å»é‡å¹¶æ’åº

async def image_to_base64(image_path):
    """å¼‚æ­¥å°†å›¾ç‰‡è½¬æ¢ä¸ºBase64ç¼–ç """
    async with aiofiles.open(image_path, "rb") as img_file:
        content = await img_file.read()
        return base64.b64encode(content).decode('utf-8')

def get_image_type(image_path: str) -> str:
    """æ£€æµ‹å›¾ç‰‡ç±»å‹"""
    img_type = 'jpeg'  # é»˜è®¤
    try:
        kind = filetype.guess(image_path)
        if kind and kind.mime.startswith('image/'):
            img_type = kind.extension
            if img_type == 'jpg':
                img_type = 'jpeg'
    except Exception:
        return 'jpeg' # é»˜è®¤
    return img_type

def resize_image_if_needed(image_path: str, max_size: int = 2000) -> Optional[bytes]:
    """
    å¦‚æœå›¾ç‰‡å°ºå¯¸è¶…è¿‡æœ€å¤§å€¼ï¼Œåˆ™è¿›è¡Œç­‰æ¯”å‹ç¼©ã€‚

    Args:
        image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„ã€‚
        max_size: å…è®¸çš„æœ€å¤§å°ºå¯¸ï¼ˆå®½æˆ–é«˜ï¼‰ã€‚

    Returns:
        å¦‚æœè¿›è¡Œäº†å‹ç¼©ï¼Œåˆ™è¿”å›å‹ç¼©åçš„å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ® (bytes)ï¼›å¦åˆ™è¿”å› Noneã€‚
    """
    try:
        with Image.open(image_path) as img:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„å›¾åƒæ•°æ®
            try:
                img.verify()
                # é‡æ–°æ‰“å¼€ä»¥è¿›è¡Œæ“ä½œ
                img = Image.open(image_path)
            except Exception:
                # å¯¹äºæŸåçš„æˆ–éæ ‡å‡†å›¾åƒï¼Œç›´æ¥è·³è¿‡å‹ç¼©
                return None

            width, height = img.size
            if width > max_size or height > max_size:
                print(f"{Fore.YELLOW}å›¾ç‰‡å°ºå¯¸ ({width}x{height}) è¶…å‡º {max_size}pxï¼Œå°è¯•å‹ç¼©...{Style.RESET_ALL}")
                
                # è®¡ç®—ç­‰æ¯”ç¼©æ”¾åçš„å°ºå¯¸
                if width > height:
                    new_width = max_size
                    new_height = int(max_size * height / width)
                else:
                    new_height = max_size
                    new_width = int(max_size * width / height)
                
                # ä½¿ç”¨é«˜è´¨é‡çš„LANCZOSé‡‡æ ·è¿›è¡Œç¼©æ”¾
                resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
                # å°†å‹ç¼©åçš„å›¾ç‰‡ä¿å­˜åˆ°å†…å­˜
                byte_arr = io.BytesIO()
                # ç¡®å®šåŸå§‹æ ¼å¼ä»¥è¿›è¡Œä¿å­˜
                img_format = img.format if img.format in ['JPEG', 'PNG', 'WEBP'] else 'JPEG'
                resized_img.save(byte_arr, format=img_format)
                
                return byte_arr.getvalue()
    except FileNotFoundError:
        # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•å¤„ç†
        return None
    except Exception as e:
        # æ•è·æ‰€æœ‰å…¶ä»–Pillowç›¸å…³çš„å¼‚å¸¸
        print(f"{Fore.RED}å¤„ç†å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}{Style.RESET_ALL}")
        return None
        
    return None

def extract_xml_result(text: str) -> Dict:
    """ä»æ¨¡å‹è¾“å‡ºä¸­æå–XMLå†…å®¹ï¼ˆå¢å¼ºé²æ£’æ€§ï¼‰"""
    try:
        # ç­–ç•¥1: æå–<result>æ ‡ç­¾å—ï¼ˆæœ€å¸¸è§ï¼‰
        xml_patterns = [
            r'<result[^>]*>(.*?)</result>',  # æ ‡å‡†resultæ ‡ç­¾
            r'```xml\s*<result[^>]*>(.*?)</result>\s*```',  # markdownåŒ…è£…çš„XML
            r'```\s*<result[^>]*>(.*?)</result>\s*```',  # æ— xmlæ ‡è¯†çš„ä»£ç å—
            r'<result[^>]*>(.*?)(?=\n\n|\Z)',  # ä¸å®Œæ•´çš„resultæ ‡ç­¾
        ]
        
        xml_content = None
        for pattern in xml_patterns:
            match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
            if match:
                xml_content = f"<result>{match.group(1)}</result>"
                break
        
        # ç­–ç•¥2: å¦‚æœæ‰¾ä¸åˆ°resultæ ‡ç­¾ï¼Œå°è¯•æå–ç‹¬ç«‹çš„XMLå­—æ®µ
        if not xml_content:
            xml_fields = {}
            field_patterns = {
                'is_ai_generated': r'<is_ai_generated[^>]*>(.*?)</is_ai_generated>',
                'watermark_present': r'<watermark_present[^>]*>(.*?)</watermark_present>',
                'watermark_location': r'<watermark_location[^>]*>(.*?)</watermark_location>',
                'score': r'<score[^>]*>(.*?)</score>',
                'feedback': r'<feedback[^>]*>(.*?)</feedback>'
            }
            
            for field, pattern in field_patterns.items():
                match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
                if match:
                    xml_fields[field] = match.group(1).strip()
            
            if xml_fields:
                # é‡å»ºXML
                xml_parts = ['<result>']
                for field, value in xml_fields.items():
                    xml_parts.append(f'<{field}>{value}</{field}>')
                xml_parts.append('</result>')
                xml_content = ''.join(xml_parts)
        
        if not xml_content:
            return {
                "error": "XML_NOT_FOUND",
                "raw_output": text[:500] + "..." if len(text) > 500 else text
            }
        
        # æ¸…ç†XMLå†…å®¹
        xml_content = re.sub(r'```xml\s*', '', xml_content)
        xml_content = re.sub(r'\s*```', '', xml_content)
        xml_content = xml_content.strip()
        
        # è§£æXML
        try:
            result_dict = xmltodict.parse(xml_content, dict_constructor=dict)['result']
        except Exception as parse_error:
            # å¦‚æœxmltodictå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨è§£æ
            manual_result = {}
            for field in ['is_ai_generated', 'watermark_present', 'watermark_location', 'score', 'feedback']:
                pattern = f'<{field}[^>]*>(.*?)</{field}>'
                match = re.search(pattern, xml_content, re.DOTALL | re.IGNORECASE)
                if match:
                    manual_result[field] = match.group(1).strip()
            
            if manual_result:
                result_dict = manual_result
            else:
                raise parse_error
        
        # ç±»å‹è½¬æ¢å’ŒéªŒè¯
        processed = {}
        for key, value in result_dict.items():
            key = key.lower().strip()
            if key in ['is_ai_generated', 'watermark_present']:
                processed[key] = str(value).lower() in ['true', 'yes', '1', 'True']
            elif key == 'score':
                try:
                    if isinstance(value, str):
                        # æå–æ•°å­—
                        num_match = re.search(r'(\d+\.?\d*)', value)
                        processed[key] = round(float(num_match.group(1)), 1) if num_match else 0.0
                    else:
                        processed[key] = round(float(value), 1)
                    # ç¡®ä¿åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…
                    processed[key] = max(0.0, min(10.0, processed[key]))
                except:
                    processed[key] = 0.0
            else:
                processed[key] = str(value).strip() if value else ''
        
        # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
        required_fields = {
            'is_ai_generated': False,
            'watermark_present': False,
            'watermark_location': 'æ— ',
            'score': 0.0,
            'feedback': 'è§£ææˆåŠŸ'
        }
        
        for field, default_value in required_fields.items():
            if field not in processed:
                processed[field] = default_value
        
        return processed
        
    except Exception as e:
        return {
            "error": f"XML_PARSING_ERROR: {str(e)}",
            "raw_output": text[:500] + "..." if len(text) > 500 else text,
            "traceback": traceback.format_exc()
        }

class CostCalculator:
    """APIæˆæœ¬è®¡ç®—å™¨"""
    
    def __init__(self):
        # è±†åŒ…æ¨¡å‹å®šä»·ï¼ˆå…ƒ/ç™¾ä¸‡tokenï¼‰
        self.input_price = 0.15  # è¾“å…¥tokenä»·æ ¼
        self.output_price = 1.50  # è¾“å‡ºtokenä»·æ ¼
        
        # ç»Ÿè®¡æ•°æ®
        self.total_prompt_tokens = 0
        self.total_completion_tokens = 0
        self.total_reasoning_tokens = 0
        self.total_requests = 0
        self.successful_requests = 0
        
    def add_usage(self, api_usage):
        """æ·»åŠ APIä½¿ç”¨ç»Ÿè®¡"""
        if not api_usage:
            return
            
        self.total_requests += 1
        self.successful_requests += 1
        
        # åŸºç¡€tokenç»Ÿè®¡
        self.total_prompt_tokens += api_usage.get('prompt_tokens', 0)
        self.total_completion_tokens += api_usage.get('completion_tokens', 0)
        
        # reasoning_tokensç»Ÿè®¡ï¼ˆå±äºè¾“å‡ºtokenï¼‰
        completion_details = api_usage.get('completion_tokens_details', {})
        reasoning_tokens = completion_details.get('reasoning_tokens', 0)
        self.total_reasoning_tokens += reasoning_tokens
    
    def calculate_cost(self):
        """è®¡ç®—æ€»è´¹ç”¨ï¼ˆäººæ°‘å¸ï¼‰"""
        # è¾“å…¥æˆæœ¬
        input_cost = (self.total_prompt_tokens / 1_000_000) * self.input_price
        
        # è¾“å‡ºæˆæœ¬ï¼ˆåŒ…å«reasoning_tokensï¼‰
        total_output_tokens = self.total_completion_tokens + self.total_reasoning_tokens
        output_cost = (total_output_tokens / 1_000_000) * self.output_price
        
        total_cost = input_cost + output_cost
        
        return {
            'input_tokens': self.total_prompt_tokens,
            'output_tokens': self.total_completion_tokens,
            'reasoning_tokens': self.total_reasoning_tokens,
            'total_output_tokens': total_output_tokens,
            'input_cost': input_cost,
            'output_cost': output_cost,
            'total_cost': total_cost,
            'total_requests': self.total_requests,
            'successful_requests': self.successful_requests
        }
    
    def format_cost_report(self, processing_time=0, image_count=0):
        """æ ¼å¼åŒ–æˆæœ¬æŠ¥å‘Š"""
        cost_data = self.calculate_cost()
        
        report = f"\n{Fore.CYAN}ğŸ’° æˆæœ¬åˆ†ææŠ¥å‘Š:{Style.RESET_ALL}\n"
        report += f"{'='*50}\n"
        
        # Tokenä½¿ç”¨ç»Ÿè®¡
        report += f"{Fore.YELLOW}ğŸ“Š Tokenä½¿ç”¨ç»Ÿè®¡:{Style.RESET_ALL}\n"
        report += f"  ğŸ”¤ è¾“å…¥Token:     {Fore.GREEN}{cost_data['input_tokens']:,}{Style.RESET_ALL}\n"
        report += f"  ğŸ“ è¾“å‡ºToken:     {Fore.GREEN}{cost_data['output_tokens']:,}{Style.RESET_ALL}\n"
        if cost_data['reasoning_tokens'] > 0:
            report += f"  ğŸ§  æ¨ç†Token:     {Fore.BLUE}{cost_data['reasoning_tokens']:,}{Style.RESET_ALL}\n"
        report += f"  ğŸ“Š æ€»è¾“å‡ºToken:   {Fore.MAGENTA}{cost_data['total_output_tokens']:,}{Style.RESET_ALL}\n"
        
        # è´¹ç”¨è®¡ç®—
        report += f"\n{Fore.YELLOW}ğŸ’³ è´¹ç”¨è®¡ç®—:{Style.RESET_ALL}\n"
        report += f"  ğŸ’µ è¾“å…¥è´¹ç”¨:     {Fore.GREEN}Â¥{cost_data['input_cost']:.4f}{Style.RESET_ALL}\n"
        report += f"  ğŸ’µ è¾“å‡ºè´¹ç”¨:     {Fore.GREEN}Â¥{cost_data['output_cost']:.4f}{Style.RESET_ALL}\n"
        report += f"  ğŸ’° æ€»è´¹ç”¨:       {Fore.RED}Â¥{cost_data['total_cost']:.4f}{Style.RESET_ALL}\n"
        
        # å¹³å‡æˆæœ¬
        if image_count > 0:
            avg_cost = cost_data['total_cost'] / image_count
            report += f"  ğŸ“· å•å¼ å›¾ç‰‡æˆæœ¬: {Fore.CYAN}Â¥{avg_cost:.4f}{Style.RESET_ALL}\n"
        
        # è¯·æ±‚ç»Ÿè®¡
        report += f"\n{Fore.YELLOW}ğŸ“ˆ è¯·æ±‚ç»Ÿè®¡:{Style.RESET_ALL}\n"
        report += f"  âœ… æˆåŠŸè¯·æ±‚:     {Fore.GREEN}{cost_data['successful_requests']}{Style.RESET_ALL}\n"
        report += f"  ğŸ“Š æ€»è¯·æ±‚æ•°:     {Fore.BLUE}{cost_data['total_requests']}{Style.RESET_ALL}\n"
        
        # æ•ˆç‡ç»Ÿè®¡
        if processing_time > 0:
            cost_per_second = cost_data['total_cost'] / processing_time
            report += f"  â±ï¸  æ¯ç§’æˆæœ¬:     {Fore.MAGENTA}Â¥{cost_per_second:.6f}{Style.RESET_ALL}\n"
        
        report += f"{'='*50}\n"
        
        return report, cost_data 