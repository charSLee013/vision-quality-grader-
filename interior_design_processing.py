#!/usr/bin/env python3
"""
å®¤å†…è®¾è®¡å›¾åƒåˆ†ææ‰¹é‡å¤„ç†é€»è¾‘
é›†æˆæ£€æŸ¥ç‚¹ç®¡ç†ã€TXTæ–‡ä»¶è¾“å‡ºå’Œå¢å¼ºé”™è¯¯æ¢å¤
"""

import os
import json
import asyncio
import aiohttp
import aiofiles
import time
import traceback
from typing import List, Dict, Any
from tqdm.asyncio import tqdm

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from batch_task_pool import BatchTaskPool
from interior_design_analyzer import InteriorDesignAnalyzer
from vlm_common import (
    validate_batch_config, find_images, CostCalculator,
    quick_validate_image, Fore, Style, convert_score_to_range
)


async def process_single_interior_design_image(analyzer, session, img_path, force_rerun, debug_mode, cost_calculator):
    """
    å¤„ç†å•ä¸ªå®¤å†…è®¾è®¡å›¾ç‰‡çš„å¼‚æ­¥å‡½æ•°
    
    Args:
        analyzer: InteriorDesignAnalyzerå®ä¾‹
        session: aiohttpä¼šè¯å¯¹è±¡
        img_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        force_rerun: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†
        debug_mode: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
        cost_calculator: æˆæœ¬è®¡ç®—å™¨å®ä¾‹
        
    Returns:
        Dict: å¤„ç†ç»“æœ
    """
    txt_path = os.path.splitext(img_path)[0] + '.txt'

    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°å¤„ç† - ç®€å•æ£€æŸ¥TXTæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰ä¸¤è¡Œå†…å®¹
    if not force_rerun and txt_file_exists_with_content(txt_path):
        return {"status": "skipped", "path": img_path}
    
    # åˆ†æå›¾ç‰‡
    result = await analyzer.analyze_image(session, img_path)
    
    if result and "error" not in result:
        try:
            # ç»Ÿè®¡APIä½¿ç”¨æˆæœ¬
            if "api_usage" in result:
                cost_calculator.add_usage(result["api_usage"])
            
            # æ„å»ºTXTæ–‡ä»¶å†…å®¹
            content_lines = []

            # ç¬¬ä¸€è¡Œï¼štagsï¼ˆå¯èƒ½åŒ…å«scoreå‰ç¼€ï¼‰
            tags_content = ''
            if 'tags' in result and result['tags']:
                tags_content = result['tags']

            # å°è¯•ä»å¯¹åº”çš„JSONæ–‡ä»¶ä¸­è¯»å–scoreä¿¡æ¯
            score_prefix = ''
            try:
                json_path = os.path.splitext(img_path)[0] + '.json'
                if os.path.exists(json_path):
                    async with aiofiles.open(json_path, 'r', encoding='utf-8') as f:
                        json_content = await f.read()
                        json_data = json.loads(json_content)

                        if 'score' in json_data:
                            score_value = float(json_data['score'])
                            converted_score = convert_score_to_range(score_value)
                            score_prefix = f'score_{converted_score}, '

                            if debug_mode:
                                print(f"{Fore.CYAN}ğŸ“Š å‘ç°è¯„åˆ†: {score_value} -> score_{converted_score}{Style.RESET_ALL}")

            except Exception as e:
                # JSONè¯»å–å¤±è´¥æ—¶é™é»˜å¤„ç†ï¼Œä¸å½±å“ä¸»æµç¨‹
                if debug_mode:
                    print(f"{Fore.YELLOW}âš ï¸ JSONè¯»å–å¤±è´¥: {e}{Style.RESET_ALL}")

            # ç»„åˆæœ€ç»ˆçš„tagså†…å®¹
            final_tags = score_prefix + tags_content if tags_content else score_prefix.rstrip(', ')
            content_lines.append(final_tags)
                
            # ç¬¬äºŒè¡Œï¼šdetail
            if 'detail' in result and result['detail']:
                content_lines.append(result['detail'])
            else:
                content_lines.append('')  # ç©ºè¡Œå ä½
            
            # å¼‚æ­¥ä¿å­˜TXTæ–‡ä»¶
            os.makedirs(os.path.dirname(txt_path), exist_ok=True)
            async with aiofiles.open(txt_path, 'w', encoding='utf-8') as f:
                await f.write('\n'.join(content_lines))

            return {"status": "success", "path": img_path, "result": result}
            
        except Exception as e:
            return {
                "status": "save_error",
                "path": img_path,
                "error": str(e),
                "result": result
            }
    else:
        # åˆ†æå¤±è´¥ï¼Œç»Ÿè®¡è¯·æ±‚æ•°
        cost_calculator.total_requests += 1
        return {
            "status": "analysis_error",
            "path": img_path,
            "error": result
        }


def txt_file_exists_with_content(txt_path: str) -> bool:
    """æ£€æŸ¥TXTæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰ä¸¤è¡Œå†…å®¹"""
    if not os.path.exists(txt_path):
        return False

    try:
        with open(txt_path, 'r', encoding='utf-8') as f:
            lines = f.read().strip().split('\n')
            return len(lines) >= 2 and any(line.strip() for line in lines)
    except Exception:
        return False


async def process_images_interior_design(root_dir: str, force_rerun: bool = False, debug: bool = False, concurrent_limit: int = None) -> int:
    """
    æ‰¹é‡å¤„ç†å®¤å†…è®¾è®¡å›¾ç‰‡çš„ä¸»å‡½æ•°

    Args:
        root_dir: å›¾ç‰‡æ ¹ç›®å½•
        force_rerun: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†
        debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
        concurrent_limit: å¹¶å‘é™åˆ¶æ•°é‡

    Returns:
        int: é€€å‡ºä»£ç  (0=æˆåŠŸ, 1=å¤±è´¥)
    """
    try:
        start_time = time.time()

        # éªŒè¯é…ç½®
        validate_batch_config()

        # è·å–å¹¶å‘é™åˆ¶
        concurrent_limit = concurrent_limit or int(os.getenv('VLM_BATCH_CONCURRENT_LIMIT', '50000'))

        # åˆå§‹åŒ–ç»„ä»¶
        task_pool = BatchTaskPool(max_concurrent=concurrent_limit)
        analyzer = InteriorDesignAnalyzer()
        cost_calculator = CostCalculator()

        # æŸ¥æ‰¾å¾…å¤„ç†å›¾ç‰‡
        all_images = find_images(root_dir)

        # é¢„è¿‡æ»¤ï¼šå¿«é€ŸéªŒè¯å›¾ç‰‡æœ‰æ•ˆæ€§ï¼Œé¿å…å¤„ç†æ— æ•ˆå›¾ç‰‡
        valid_images = []
        for img_path in all_images:
            validation = quick_validate_image(img_path, max_size=2000, min_size=100)
            if validation["valid"]:
                valid_images.append(img_path)
            elif debug:
                print(f"Skipping invalid image: {os.path.basename(img_path)} - {validation['reason']}")

        # è¿‡æ»¤å·²å¤„ç†çš„å›¾ç‰‡
        tasks_to_process = [
            img_path for img_path in valid_images
            if not txt_file_exists_with_content(os.path.splitext(img_path)[0] + '.txt') or force_rerun
        ]

        if not tasks_to_process:
            print("All images already processed.")
            return 0

        print(f"Processing {len(tasks_to_process)} images...")

        # é…ç½®è¿æ¥æ± 
        connector = aiohttp.TCPConnector(
            limit=0,  # æ— é™åˆ¶
            limit_per_host=0,  # æ— é™åˆ¶
            keepalive_timeout=3600,  # 1å°æ—¶ä¿æ´»
            enable_cleanup_closed=True
        )
        timeout = aiohttp.ClientTimeout(total=72*3600, connect=30, sock_read=3600)

        results = []
        processed_count = 0



        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            # åŠ¨æ€æäº¤ä»»åŠ¡åˆ°æ± ä¸­
            pending_tasks = {}

            # ä½¿ç”¨tqdmè¿›åº¦æ¡æ˜¾ç¤ºå®Œæˆè¿›åº¦
            with tqdm(total=len(tasks_to_process), desc="Processing") as pbar:

                # æäº¤æ‰€æœ‰ä»»åŠ¡
                for img_path in tasks_to_process:
                    # åˆ›å»ºå¤„ç†åç¨‹
                    coro = process_single_interior_design_image(analyzer, session, img_path, force_rerun, debug, cost_calculator)
                    task_data = {"path": img_path, "index": processed_count}

                    # æäº¤åˆ°ä»»åŠ¡æ± ï¼ˆå¦‚æœæ± æ»¡ä¼šç­‰å¾…ï¼‰
                    task_id, task = await task_pool.submit_task(coro, task_data)
                    pending_tasks[task_id] = {"task": task, "data": task_data}

                    processed_count += 1

                # æ”¶é›†å®Œæˆçš„ä»»åŠ¡å¹¶æ›´æ–°è¿›åº¦æ¡
                while pending_tasks:
                    completed_task_ids = []
                    for task_id, task_info in pending_tasks.items():
                        if task_info["task"].done():
                            try:
                                result = await task_info["task"]
                                results.append(result)

                                # æ›´æ–°è¿›åº¦æ¡
                                pbar.update(1)

                                # æ˜¾ç¤ºå½“å‰å¤„ç†çš„æ–‡ä»¶åå’ŒçŠ¶æ€
                                filename = os.path.basename(result.get("path", "unknown"))
                                if result.get("status") == "success":
                                    pbar.set_postfix_str(f"âœ“ {filename}")
                                else:
                                    pbar.set_postfix_str(f"âœ— {filename}")

                            except Exception as e:
                                results.append({
                                    "status": "collection_error",
                                    "path": task_info["data"]["path"],
                                    "error": str(e)
                                })
                                pbar.update(1)
                                filename = os.path.basename(task_info["data"]["path"])
                                pbar.set_postfix_str(f"âœ— {filename}")

                            completed_task_ids.append(task_id)

                    # ç§»é™¤å·²å®Œæˆçš„ä»»åŠ¡
                    for task_id in completed_task_ids:
                        pending_tasks.pop(task_id)

                    # çŸ­æš‚ç­‰å¾…ï¼Œé¿å…è¿‡åº¦å ç”¨CPU
                    if pending_tasks:
                        await asyncio.sleep(0.1)

        # ç»Ÿè®¡ç»“æœ
        processing_time = time.time() - start_time
        success_count = sum(1 for r in results if r["status"] == "success")
        skip_count = sum(1 for r in results if r["status"] == "skipped")
        error_count = len(results) - success_count - skip_count

        print(f"\nCompleted {success_count}/{len(tasks_to_process)} images in {processing_time:.1f}s")

        # æ˜¾ç¤ºæˆæœ¬æŠ¥å‘Š
        cost_report, cost_data = cost_calculator.format_cost_report(processing_time, success_count)
        print(cost_report)

        return 0

    except Exception as e:
        print(f"ERROR: {e}")
        if debug:
            import traceback
            print(traceback.format_exc())
        return 1
