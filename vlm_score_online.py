#!/usr/bin/env python3
"""
VLMå›¾ç‰‡è´¨é‡è¯„åˆ† - åœ¨çº¿æ¨ç†ç‰ˆæœ¬
ä½¿ç”¨å¼‚æ­¥å¹¶å‘å¤„ç†è¿›è¡Œå®æ—¶å›¾ç‰‡è´¨é‡åˆ†æ
"""

import os
import json
import argparse
import asyncio
import aiohttp
import aiofiles
from tqdm.asyncio import tqdm
import traceback
import time

# å¯¼å…¥å…±äº«å·¥å…·æ¨¡å—
from vlm_common import (
    validate_config, find_images, image_to_base64, get_image_type,
    extract_xml_result, CostCalculator, USER_PROMPT,
    Fore, Style
)

class ImageQualityAnalyzer:
    def __init__(self, model_name=None, concurrent_limit=None):
        """åˆå§‹åŒ–å¼‚æ­¥APIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®"""
        self.api_endpoint = os.getenv('VLM_API_ENDPOINT')
        self.api_token = os.getenv('VLM_API_TOKEN')
        self.model_name = model_name or os.getenv('VLM_MODEL_NAME')
        self.max_tokens = int(os.getenv('VLM_MAX_TOKENS', '16384'))
        self.temperature = float(os.getenv('VLM_TEMPERATURE', '0.3'))
        self.timeout = int(os.getenv('VLM_TIMEOUT', '180'))
        self.concurrent_limit = concurrent_limit or int(os.getenv('CONCURRENT_LIMIT', '3'))
        
        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘
        self.semaphore = asyncio.Semaphore(self.concurrent_limit)
        
        # æ„å»ºè¯·æ±‚å¤´ï¼ŒåŒ…å«è®¤è¯ä¿¡æ¯
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_token}"
        }
    
    def _build_payload(self, base64_image, img_type):
        """æ„å»ºAPIè¯·æ±‚è´Ÿè½½ï¼Œé€‚é…Volces APIæ ¼å¼"""
        return {
            "model": self.model_name,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": USER_PROMPT
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{img_type};base64,{base64_image}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": self.max_tokens,
            "temperature": self.temperature
        }

    async def analyze_image(self, session, image_path):
        """é€šè¿‡VLM APIå¼‚æ­¥åˆ†æå•å¼ å›¾ç‰‡"""
        async with self.semaphore:  # æ§åˆ¶å¹¶å‘æ•°é‡
            try:
                # å¼‚æ­¥è¯»å–å’Œç¼–ç å›¾ç‰‡
                base64_image = await image_to_base64(image_path)
                
                # æ£€æµ‹å›¾ç‰‡ç±»å‹
                img_type = get_image_type(image_path)
                
                # æ„å»ºè¯·æ±‚è´Ÿè½½
                payload = self._build_payload(base64_image, img_type)
                
                # å‘é€å¼‚æ­¥è¯·æ±‚
                async with session.post(
                    self.api_endpoint,
                    headers=self.headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=self.timeout)
                ) as response:
                    
                    if response.status != 200:
                        error_text = await response.text()
                        error_msg = f"APIé”™è¯¯ ({response.status})"
                        
                        try:
                            error_data = await response.json()
                            error_msg += f": {error_data.get('message', 'æœªçŸ¥é”™è¯¯')}"
                        except:
                            error_msg += f": {error_text[:200]}"
                        
                        return {
                            "error": "API_ERROR",
                            "message": error_msg,
                            "status_code": response.status
                        }
                    
                    # è§£æå“åº”
                    response_data = await response.json()
                    
                    if "choices" not in response_data or len(response_data["choices"]) == 0:
                        return {
                            "error": "NO_RESPONSE",
                            "message": "APIè¿”å›äº†ç©ºå“åº”"
                        }
                    
                    content = response_data["choices"][0]["message"]["content"]
                    
                    # æå–XMLç»“æœ
                    result = extract_xml_result(content)
                    
                    # æ·»åŠ å…ƒæ•°æ®
                    if isinstance(result, dict) and "error" not in result:
                        result["api_usage"] = response_data.get("usage", {})
                        result["api_provider"] = "volces"
                    
                    return result
                    
            except asyncio.TimeoutError:
                return {
                    "error": "TIMEOUT_ERROR",
                    "message": f"è¯·æ±‚è¶…æ—¶ (è¶…è¿‡ {self.timeout} ç§’)"
                }
            except aiohttp.ClientError as e:
                return {
                    "error": "CONNECTION_ERROR",
                    "message": f"ç½‘ç»œè¿æ¥å¤±è´¥: {str(e)}"
                }
            except Exception as e:
                return {
                    "error": "EXCEPTION",
                    "message": str(e),
                    "traceback": traceback.format_exc()
                }

async def process_single_image(analyzer, session, img_path, force_rerun, debug_mode, cost_calculator):
    """å¤„ç†å•ä¸ªå›¾ç‰‡çš„å¼‚æ­¥å‡½æ•°"""
    json_path = os.path.splitext(img_path)[0] + '.json'
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°å¤„ç†
    if os.path.exists(json_path) and not force_rerun:
        return {"status": "skipped", "path": img_path}
    
    # åˆ†æå›¾ç‰‡
    result = await analyzer.analyze_image(session, img_path)
    
    if result and "error" not in result:
        try:
            # ç»Ÿè®¡APIä½¿ç”¨æˆæœ¬
            if "api_usage" in result:
                cost_calculator.add_usage(result["api_usage"])
            
            # å¼‚æ­¥ä¿å­˜ç»“æœ
            os.makedirs(os.path.dirname(json_path), exist_ok=True)
            async with aiofiles.open(json_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(result, ensure_ascii=False, indent=2))
            return {"status": "success", "path": img_path, "result": result}
        except Exception as e:
            return {
                "status": "save_error", 
                "path": img_path, 
                "error": str(e),
                "result": result
            }
    else:
        # å³ä½¿å¤±è´¥ä¹Ÿè¦ç»Ÿè®¡è¯·æ±‚æ•°
        cost_calculator.total_requests += 1
        return {
            "status": "analysis_error", 
            "path": img_path, 
            "error": result
        }

async def main():
    parser = argparse.ArgumentParser(description='å¼‚æ­¥æ‰¹é‡åˆ†æå›¾ç‰‡è´¨é‡ - åœ¨çº¿æ¨ç†ç‰ˆæœ¬')
    parser.add_argument('root_dir', type=str, help='åŒ…å«å›¾ç‰‡çš„æ ¹ç›®å½•')
    parser.add_argument('--force-rerun', action='store_true', help='å¼ºåˆ¶é‡æ–°å¤„ç†å·²å­˜åœ¨çš„ç»“æœæ–‡ä»¶')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--concurrent-limit', type=int, help='å¹¶å‘é™åˆ¶æ•°é‡')
    args = parser.parse_args()

    try:
        start_time = time.time()
        
        # éªŒè¯é…ç½®
        validate_config()
        
        # åˆå§‹åŒ–åˆ†æå™¨å’Œæˆæœ¬è®¡ç®—å™¨
        analyzer = ImageQualityAnalyzer(concurrent_limit=args.concurrent_limit)
        cost_calculator = CostCalculator()
        
        # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡
        all_images = find_images(args.root_dir)
        
        # è¿‡æ»¤éœ€è¦å¤„ç†çš„ä»»åŠ¡
        tasks_to_process = []
        skipped_count = 0
        
        for img_path in all_images:
            json_path = os.path.splitext(img_path)[0] + '.json'
            if not os.path.exists(json_path) or args.force_rerun:
                tasks_to_process.append(img_path)
            else:
                skipped_count += 1

        # ç¾åŒ–çš„ç»Ÿè®¡ä¿¡æ¯è¾“å‡º
        print(f"\n{Fore.CYAN}ğŸ“Š åœ¨çº¿æ¨ç†å¤„ç†ç»Ÿè®¡:{Style.RESET_ALL}")
        print(f"  ğŸ“ æ‰«æç›®å½•: {Fore.YELLOW}{args.root_dir}{Style.RESET_ALL}")
        print(f"  ğŸ–¼ï¸  å‘ç°å›¾ç‰‡: {Fore.GREEN}{len(all_images)}{Style.RESET_ALL} å¼ ")
        print(f"  â­ï¸  å·²å¤„ç†: {Fore.BLUE}{skipped_count}{Style.RESET_ALL} å¼  (è·³è¿‡)")
        print(f"  ğŸ”„ å¾…å¤„ç†: {Fore.MAGENTA}{len(tasks_to_process)}{Style.RESET_ALL} å¼ ")
        
        if len(tasks_to_process) == 0:
            print(f"\n{Fore.GREEN}âœ… æ‰€æœ‰å›¾ç‰‡éƒ½å·²å¤„ç†å®Œæˆï¼{Style.RESET_ALL}")
            return 0
        
        print(f"\n{Fore.YELLOW}ğŸš€ å¼€å§‹åœ¨çº¿æ¨ç†å¤„ç†...{Style.RESET_ALL}")
        
        # åˆ›å»ºå¼‚æ­¥HTTPä¼šè¯
        connector = aiohttp.TCPConnector(limit=50, limit_per_host=10)
        timeout = aiohttp.ClientTimeout(total=300)
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            # åˆ›å»ºæ‰€æœ‰å¤„ç†ä»»åŠ¡
            processing_tasks = [
                process_single_image(analyzer, session, img_path, args.force_rerun, args.debug, cost_calculator)
                for img_path in tasks_to_process
            ]
            
            # å¼‚æ­¥æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼Œå¸¦è¿›åº¦æ¡
            results = []
            
            # ä½¿ç”¨tqdmçš„å¼‚æ­¥è¿›åº¦æ¡
            with tqdm(total=len(processing_tasks), desc=f"{Fore.GREEN}å¤„ç†è¿›åº¦{Style.RESET_ALL}") as pbar:
                for coro in asyncio.as_completed(processing_tasks):
                    result = await coro
                    results.append(result)
                    pbar.update(1)
                    
                    # å®æ—¶æ˜¾ç¤ºå¤„ç†çŠ¶æ€
                    if result["status"] == "success":
                        pbar.set_postfix_str(f"{Fore.GREEN}âœ“{Style.RESET_ALL} {os.path.basename(result['path'])}")
                    elif result["status"] == "analysis_error":
                        pbar.set_postfix_str(f"{Fore.RED}âœ—{Style.RESET_ALL} {os.path.basename(result['path'])}")
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r["status"] == "success")
        skipped_count_new = sum(1 for r in results if r["status"] == "skipped")
        error_count = len(results) - success_count - skipped_count_new
        
        # å¤„ç†é”™è¯¯æ—¥å¿—
        error_log = []
        for result in results:
            if result["status"] in ["analysis_error", "save_error"]:
                img_path = result["path"]
                if result["status"] == "analysis_error":
                    error_info = result["error"]
                    error_entry = {
                        "file": img_path,
                        "error_type": error_info.get("error", "UNKNOWN_ERROR"),
                        "message": error_info.get("message", "æœªçŸ¥é”™è¯¯"),
                        "raw_output": error_info.get("raw_output", ""),
                        "traceback": error_info.get("traceback", ""),
                        "status_code": error_info.get("status_code", "")
                    }
                else:  # save_error
                    error_entry = {
                        "file": img_path,
                        "error_type": "SAVE_ERROR",
                        "message": result["error"],
                        "analysis_result": result.get("result", {})
                    }
                
                error_log.append(error_entry)
                
                # å®æ—¶æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                print(f"\n{Fore.RED}âŒ å¤„ç†å¤±è´¥{Style.RESET_ALL} {os.path.basename(img_path)}:")
                print(f"   {Fore.YELLOW}é”™è¯¯ç±»å‹:{Style.RESET_ALL} {error_entry.get('error_type', 'UNKNOWN')}")
                print(f"   {Fore.YELLOW}é”™è¯¯ä¿¡æ¯:{Style.RESET_ALL} {error_entry.get('message', 'æœªçŸ¥é”™è¯¯')}")
                
                if args.debug and error_entry.get('raw_output'):
                    print(f"   {Fore.CYAN}åŸå§‹è¾“å‡º:{Style.RESET_ALL} {error_entry['raw_output'][:100]}...")
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        end_time = time.time()
        processing_time = end_time - start_time
        
        # æœ€ç»ˆç»Ÿè®¡è¾“å‡º
        print(f"\n{Fore.GREEN}ğŸ‰ åœ¨çº¿æ¨ç†å¤„ç†å®Œæˆï¼{Style.RESET_ALL}")
        print(f"  âœ… æˆåŠŸ: {Fore.GREEN}{success_count}{Style.RESET_ALL}/{len(tasks_to_process)}")
        print(f"  âŒ å¤±è´¥: {Fore.RED}{error_count}{Style.RESET_ALL}")
        print(f"  â±ï¸  è€—æ—¶: {Fore.BLUE}{processing_time:.1f}{Style.RESET_ALL} ç§’")
        print(f"  ğŸš€ å¹³å‡é€Ÿåº¦: {Fore.MAGENTA}{len(tasks_to_process)/processing_time:.1f}{Style.RESET_ALL} å¼ /ç§’")
        
        # æ˜¾ç¤ºæˆæœ¬æŠ¥å‘Š
        cost_report, cost_data = cost_calculator.format_cost_report(processing_time, success_count)
        print(cost_report)
        
        # ä¿å­˜é”™è¯¯æ—¥å¿—
        if error_log:
            log_file = 'processing_errors_online.jsonl'
            async with aiofiles.open(log_file, 'w', encoding='utf-8') as f:
                for entry in error_log:
                    await f.write(json.dumps(entry, ensure_ascii=False) + '\n')
            print(f"  ğŸ“ é”™è¯¯æ—¥å¿—: {Fore.YELLOW}{log_file}{Style.RESET_ALL}")
                    
    except ValueError as e:
        print(f"{Fore.RED}âŒ é…ç½®é”™è¯¯:{Style.RESET_ALL} {e}")
        print("è¯·ç¡®ä¿ .env æ–‡ä»¶å­˜åœ¨å¹¶åŒ…å«æ‰€æœ‰å¿…éœ€çš„é…ç½®é¡¹ã€‚")
        return 1
    except Exception as e:
        print(f"{Fore.RED}âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥:{Style.RESET_ALL} {e}")
        if args.debug:
            print(traceback.format_exc())
        return 1
        
    return 0

if __name__ == "__main__":
    exit(asyncio.run(main())) 