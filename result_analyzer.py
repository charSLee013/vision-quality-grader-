#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import glob
import json
import argparse
import traceback
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
from colorama import init, Fore, Style
import pandas as pd

# åˆå§‹åŒ–coloramaç”¨äºå½©è‰²è¾“å‡º
init(autoreset=True)

class JsonValidator:
    """JSONç»“æœæ–‡ä»¶éªŒè¯å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–éªŒè¯å™¨ï¼Œå®šä¹‰é¢„æœŸçš„å­—æ®µç»“æ„å’ŒéªŒè¯è§„åˆ™"""
        # å¿…éœ€å­—æ®µå®šä¹‰
        self.required_fields = {
            'is_ai_generated': bool,
            'watermark_present': bool,
            'watermark_location': str,
            'score': (int, float),
            'feedback': str,
            'api_usage': dict,
            'api_provider': str
        }
        
        # APIä½¿ç”¨ä¿¡æ¯çš„å¿…éœ€å­å­—æ®µ
        self.api_usage_fields = {
            'prompt_tokens': int,
            'completion_tokens': int,
            'total_tokens': int
        }
        
        # æ•°å€¼èŒƒå›´çº¦æŸ
        self.value_constraints = {
            'score': (0.0, 10.0),
            'prompt_tokens': (0, float('inf')),
            'completion_tokens': (0, float('inf')),
            'total_tokens': (0, float('inf'))
        }
        
        # ç»Ÿè®¡è®¡æ•°å™¨
        self.validation_stats = {
            'total_files': 0,
            'valid_files': 0,
            'invalid_files': 0,
            'parse_errors': 0,
            'field_errors': 0,
            'type_errors': 0,
            'range_errors': 0
        }
        
        # è¯¦ç»†é”™è¯¯è®°å½•
        self.detailed_errors = []
    
    def validate_single_file(self, file_path: str) -> Dict[str, Any]:
        """
        éªŒè¯å•ä¸ªJSONæ–‡ä»¶
        
        Args:
            file_path: JSONæ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        self.validation_stats['total_files'] += 1
        
        validation_result = {
            'file_path': file_path,
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'data': None
        }
        
        try:
            # å°è¯•è¯»å–å’Œè§£æJSONæ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            validation_result['data'] = data
            
            # æ‰§è¡Œå„é¡¹éªŒè¯
            field_errors = self._validate_required_fields(data)
            if field_errors:
                validation_result['errors'].extend(field_errors)
                validation_result['is_valid'] = False
                self.validation_stats['field_errors'] += 1
            
            type_errors = self._validate_field_types(data)
            if type_errors:
                validation_result['errors'].extend(type_errors)
                validation_result['is_valid'] = False
                self.validation_stats['type_errors'] += 1
            
            range_errors = self._validate_value_ranges(data)
            if range_errors:
                validation_result['errors'].extend(range_errors)
                validation_result['is_valid'] = False
                self.validation_stats['range_errors'] += 1
            
            # ç”Ÿæˆè­¦å‘Šä¿¡æ¯
            warnings = self._generate_warnings(data)
            validation_result['warnings'].extend(warnings)
            
            if validation_result['is_valid']:
                self.validation_stats['valid_files'] += 1
            else:
                self.validation_stats['invalid_files'] += 1
                
        except json.JSONDecodeError as e:
            validation_result['is_valid'] = False
            validation_result['errors'].append(f"JSONè§£æé”™è¯¯: {str(e)}")
            self.validation_stats['parse_errors'] += 1
            self.validation_stats['invalid_files'] += 1
            
        except Exception as e:
            validation_result['is_valid'] = False
            validation_result['errors'].append(f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
            self.validation_stats['invalid_files'] += 1
        
        # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
        if not validation_result['is_valid']:
            self.detailed_errors.append(validation_result)
            
        return validation_result
    
    def _validate_required_fields(self, data: Dict) -> List[str]:
        """éªŒè¯å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨"""
        errors = []
        
        for field_name in self.required_fields.keys():
            if field_name not in data:
                errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field_name}")
        
        # éªŒè¯api_usageå­å­—æ®µ
        if 'api_usage' in data and isinstance(data['api_usage'], dict):
            for sub_field in self.api_usage_fields.keys():
                if sub_field not in data['api_usage']:
                    errors.append(f"api_usageä¸­ç¼ºå°‘å­—æ®µ: {sub_field}")
        
        return errors
    
    def _validate_field_types(self, data: Dict) -> List[str]:
        """éªŒè¯å­—æ®µæ•°æ®ç±»å‹"""
        errors = []
        
        for field_name, expected_type in self.required_fields.items():
            if field_name in data:
                value = data[field_name]
                if not isinstance(value, expected_type):
                    errors.append(f"å­—æ®µ {field_name} ç±»å‹é”™è¯¯: æœŸæœ› {expected_type.__name__}, å®é™… {type(value).__name__}")
        
        # éªŒè¯api_usageå­å­—æ®µç±»å‹
        if 'api_usage' in data and isinstance(data['api_usage'], dict):
            for sub_field, expected_type in self.api_usage_fields.items():
                if sub_field in data['api_usage']:
                    value = data['api_usage'][sub_field]
                    if not isinstance(value, expected_type):
                        errors.append(f"api_usage.{sub_field} ç±»å‹é”™è¯¯: æœŸæœ› {expected_type.__name__}, å®é™… {type(value).__name__}")
        
        return errors
    
    def _validate_value_ranges(self, data: Dict) -> List[str]:
        """éªŒè¯æ•°å€¼èŒƒå›´"""
        errors = []
        
        # éªŒè¯scoreèŒƒå›´
        if 'score' in data:
            score = data['score']
            if isinstance(score, (int, float)):
                min_val, max_val = self.value_constraints['score']
                if not (min_val <= score <= max_val):
                    errors.append(f"scoreå€¼è¶…å‡ºèŒƒå›´: {score} (åº”åœ¨ {min_val}-{max_val} ä¹‹é—´)")
        
        # éªŒè¯tokenæ•°é‡
        if 'api_usage' in data and isinstance(data['api_usage'], dict):
            for field in ['prompt_tokens', 'completion_tokens', 'total_tokens']:
                if field in data['api_usage']:
                    value = data['api_usage'][field]
                    if isinstance(value, int):
                        min_val, _ = self.value_constraints[field]
                        if value < min_val:
                            errors.append(f"api_usage.{field} å€¼æ— æ•ˆ: {value} (åº” >= {min_val})")
        
        return errors
    
    def _generate_warnings(self, data: Dict) -> List[str]:
        """ç”Ÿæˆè­¦å‘Šä¿¡æ¯"""
        warnings = []
        
        # æ£€æŸ¥feedbackæ˜¯å¦ä¸ºç©º
        if 'feedback' in data and not data['feedback'].strip():
            warnings.append("feedbackå­—æ®µä¸ºç©º")
        
        # æ£€æŸ¥scoreæ˜¯å¦è¿‡ä½
        if 'score' in data and isinstance(data['score'], (int, float)):
            if data['score'] < 3.0:
                warnings.append(f"scoreå€¼è¾ƒä½: {data['score']}")
        
        # æ£€æŸ¥APIæä¾›å•†æ˜¯å¦ç¬¦åˆé¢„æœŸ
        if 'api_provider' in data and data['api_provider'] != 'volces':
            warnings.append(f"æ„å¤–çš„APIæä¾›å•†: {data['api_provider']}")
        
        return warnings

class CostAnalyzer:
    """æˆæœ¬åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æˆæœ¬åˆ†æå™¨ï¼Œä½¿ç”¨ä¸vlm_score.pyç›¸åŒçš„å®šä»·æ¨¡å‹"""
        # è±†åŒ…æ¨¡å‹å®šä»·ï¼ˆå…ƒ/ç™¾ä¸‡tokenï¼‰
        self.input_price = 0.15  # è¾“å…¥tokenä»·æ ¼
        self.output_price = 1.50  # è¾“å‡ºtokenä»·æ ¼
        
        # ç»Ÿè®¡æ•°æ®
        self.cost_stats = {
            'total_files_analyzed': 0,
            'successful_analyses': 0,
            'total_prompt_tokens': 0,
            'total_completion_tokens': 0,
            'total_reasoning_tokens': 0,
            'total_tokens': 0,
            'total_input_cost': 0.0,
            'total_output_cost': 0.0,
            'total_cost': 0.0,
            'average_cost_per_image': 0.0,
            'success_rate': 0.0
        }
        
        # è¯¦ç»†çš„per-fileæˆæœ¬æ•°æ®
        self.detailed_costs = []
    
    def analyze_costs(self, validation_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†ææ‰€æœ‰éªŒè¯ç»“æœä¸­çš„æˆæœ¬ä¿¡æ¯
        
        Args:
            validation_results: JsonValidatorç”Ÿæˆçš„éªŒè¯ç»“æœåˆ—è¡¨
            
        Returns:
            åŒ…å«è¯¦ç»†æˆæœ¬åˆ†æçš„å­—å…¸
        """
        self.cost_stats['total_files_analyzed'] = len(validation_results)
        
        for result in validation_results:
            if result['is_valid'] and result['data']:
                data = result['data']
                file_cost = self._calculate_single_file_cost(data, result['file_path'])
                
                if file_cost:
                    self.detailed_costs.append(file_cost)
                    self.cost_stats['successful_analyses'] += 1
                    
                    # ç´¯è®¡ç»Ÿè®¡
                    self.cost_stats['total_prompt_tokens'] += file_cost['prompt_tokens']
                    self.cost_stats['total_completion_tokens'] += file_cost['completion_tokens']
                    self.cost_stats['total_reasoning_tokens'] += file_cost['reasoning_tokens']
                    self.cost_stats['total_tokens'] += file_cost['total_tokens']
                    self.cost_stats['total_input_cost'] += file_cost['input_cost']
                    self.cost_stats['total_output_cost'] += file_cost['output_cost']
                    self.cost_stats['total_cost'] += file_cost['total_cost']
        
        # è®¡ç®—å¹³å‡å€¼å’Œæ•ˆç‡æŒ‡æ ‡
        self._calculate_efficiency_metrics()
        
        return self.cost_stats
    
    def _calculate_single_file_cost(self, data: Dict, file_path: str) -> Optional[Dict[str, Any]]:
        """è®¡ç®—å•ä¸ªæ–‡ä»¶çš„æˆæœ¬"""
        if 'api_usage' not in data or not isinstance(data['api_usage'], dict):
            return None
        
        api_usage = data['api_usage']
        
        # æå–tokenä½¿ç”¨ä¿¡æ¯
        prompt_tokens = api_usage.get('prompt_tokens', 0)
        completion_tokens = api_usage.get('completion_tokens', 0)
        
        # reasoning_tokenså¯èƒ½åœ¨completion_tokens_detailsä¸­
        reasoning_tokens = 0
        if 'completion_tokens_details' in api_usage:
            details = api_usage['completion_tokens_details']
            reasoning_tokens = details.get('reasoning_tokens', 0)
        
        total_tokens = prompt_tokens + completion_tokens + reasoning_tokens
        
        # è®¡ç®—æˆæœ¬
        input_cost = (prompt_tokens / 1_000_000) * self.input_price
        output_cost = ((completion_tokens + reasoning_tokens) / 1_000_000) * self.output_price
        total_cost = input_cost + output_cost
        
        return {
            'file_path': file_path,
            'prompt_tokens': prompt_tokens,
            'completion_tokens': completion_tokens,
            'reasoning_tokens': reasoning_tokens,
            'total_tokens': total_tokens,
            'input_cost': input_cost,
            'output_cost': output_cost,
            'total_cost': total_cost,
            'score': data.get('score', 0.0),
            'is_ai_generated': data.get('is_ai_generated', False),
            'watermark_present': data.get('watermark_present', False)
        }
    
    def _calculate_efficiency_metrics(self):
        """è®¡ç®—æ•ˆç‡æŒ‡æ ‡"""
        if self.cost_stats['total_files_analyzed'] > 0:
            self.cost_stats['success_rate'] = (
                self.cost_stats['successful_analyses'] / 
                self.cost_stats['total_files_analyzed'] * 100
            )
        
        if self.cost_stats['successful_analyses'] > 0:
            self.cost_stats['average_cost_per_image'] = (
                self.cost_stats['total_cost'] / 
                self.cost_stats['successful_analyses']
            )
    
    def get_cost_distribution_stats(self) -> Dict[str, Any]:
        """è·å–æˆæœ¬åˆ†å¸ƒç»Ÿè®¡"""
        if not self.detailed_costs:
            return {}
        
        costs = [item['total_cost'] for item in self.detailed_costs]
        scores = [item['score'] for item in self.detailed_costs]
        
        return {
            'cost_stats': {
                'min_cost': min(costs),
                'max_cost': max(costs),
                'median_cost': sorted(costs)[len(costs)//2],
                'cost_std': self._calculate_std(costs)
            },
            'score_stats': {
                'min_score': min(scores),
                'max_score': max(scores),
                'average_score': sum(scores) / len(scores),
                'score_std': self._calculate_std(scores)
            },
            'ai_detection_stats': {
                'ai_generated_count': sum(1 for item in self.detailed_costs if item['is_ai_generated']),
                'ai_generated_ratio': sum(1 for item in self.detailed_costs if item['is_ai_generated']) / len(self.detailed_costs) * 100
            },
            'watermark_stats': {
                'watermark_count': sum(1 for item in self.detailed_costs if item['watermark_present']),
                'watermark_ratio': sum(1 for item in self.detailed_costs if item['watermark_present']) / len(self.detailed_costs) * 100
            }
        }
    
    def get_quality_distribution_data(self) -> List[Dict[str, Any]]:
        """
        è®¡ç®—è¯¦ç»†çš„è´¨é‡åˆ†å¸ƒæ•°æ®ï¼Œç”¨äºç”Ÿæˆè¡¨æ ¼
        
        Returns:
            ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸ä»£è¡¨è¡¨æ ¼çš„ä¸€è¡Œ
        """
        if not self.detailed_costs:
            return []

        df = pd.DataFrame(self.detailed_costs)
        total_images = len(df)

        # å®šä¹‰åˆ†æ•°åŒºé—´å’Œæ ‡ç­¾
        bins = [-0.1, 2.9, 4.9, 6.9, 8.9, 10.0]
        labels = ["[0.0-2.9] ä½è´¨", "[3.0-4.9] éœ€æ”¹è¿›", "[5.0-6.9] ä¸­ç­‰", "[7.0-8.9] ä¼˜è´¨", "[9.0-10.0] ä¸“ä¸šçº§"]
        
        df['quality_range'] = pd.cut(df['score'], bins=bins, labels=labels, right=True)

        # æŒ‰è´¨é‡åŒºé—´åˆ†ç»„å¹¶èšåˆ
        distribution = df.groupby('quality_range').agg(
            count=('score', 'count'),
            ai_count=('is_ai_generated', lambda x: x.sum()),
            watermark_count=('watermark_present', lambda x: x.sum())
        ).reset_index()

        # è®¡ç®—è¡ç”ŸæŒ‡æ ‡
        distribution['percentage'] = (distribution['count'] / total_images) * 100
        distribution['ai_rate'] = (distribution['ai_count'] / distribution['count']).fillna(0) * 100
        distribution['watermark_rate'] = (distribution['watermark_count'] / distribution['count']).fillna(0) * 100
        
        # ç¡®ä¿æ‰€æœ‰åŒºé—´éƒ½å­˜åœ¨ï¼Œå³ä½¿æ•°é‡ä¸º0
        all_ranges = pd.DataFrame({'quality_range': labels})
        distribution = pd.merge(all_ranges, distribution, on='quality_range', how='left').fillna(0)

        # è½¬æ¢æ•°æ®ç±»å‹ä¸ºæ•´æ•°
        int_columns = ['count', 'ai_count', 'watermark_count']
        for col in int_columns:
            distribution[col] = distribution[col].astype(int)

        # æŒ‰ç…§æ ‡ç­¾é¡ºåºæ’åº
        distribution['quality_range'] = pd.Categorical(distribution['quality_range'], categories=labels, ordered=True)
        distribution = distribution.sort_values('quality_range')

        return distribution.to_dict('records')

    def _calculate_std(self, values: List[float]) -> float:
        """è®¡ç®—æ ‡å‡†å·®"""
        if len(values) < 2:
            return 0.0
        
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / (len(values) - 1)
        return variance ** 0.5 

class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, validator: JsonValidator, cost_analyzer: CostAnalyzer):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨"""
        self.validator = validator
        self.cost_analyzer = cost_analyzer
    
    def print_console_report(self, verbose: bool = False):
        """ç”Ÿæˆå¹¶æ‰“å°æ§åˆ¶å°æŠ¥å‘Š"""
        print(f"\n{Fore.CYAN}ğŸ“Š ç»“æœåˆ†ææŠ¥å‘Š{Style.RESET_ALL}")
        print("=" * 60)
        
        # éªŒè¯ç»Ÿè®¡æŠ¥å‘Š
        self._print_validation_summary()
        
        # æˆæœ¬åˆ†ææŠ¥å‘Š
        self._print_cost_summary()
        
        # è¯¦ç»†ç»Ÿè®¡
        self._print_detailed_stats()
        
        # å¦‚æœå¯ç”¨è¯¦ç»†æ¨¡å¼ï¼Œæ˜¾ç¤ºé”™è¯¯è¯¦æƒ…
        if verbose and self.validator.detailed_errors:
            self._print_detailed_errors()
    
    def _print_validation_summary(self):
        """æ‰“å°éªŒè¯ç»Ÿè®¡æ‘˜è¦"""
        stats = self.validator.validation_stats
        
        print(f"\n{Fore.YELLOW}ğŸ“‹ æ–‡ä»¶éªŒè¯ç»Ÿè®¡:{Style.RESET_ALL}")
        print(f"  ğŸ“ æ€»æ–‡ä»¶æ•°:     {Fore.GREEN}{stats['total_files']}{Style.RESET_ALL}")
        print(f"  âœ… æœ‰æ•ˆæ–‡ä»¶:     {Fore.GREEN}{stats['valid_files']}{Style.RESET_ALL}")
        print(f"  âŒ æ— æ•ˆæ–‡ä»¶:     {Fore.RED}{stats['invalid_files']}{Style.RESET_ALL}")
        
        if stats['total_files'] > 0:
            success_rate = (stats['valid_files'] / stats['total_files']) * 100
            print(f"  ğŸ“ˆ æˆåŠŸç‡:       {Fore.CYAN}{success_rate:.1f}%{Style.RESET_ALL}")
        
        # é”™è¯¯ç±»å‹ç»Ÿè®¡
        if stats['invalid_files'] > 0:
            print(f"\n{Fore.RED}ğŸ” é”™è¯¯ç±»å‹åˆ†å¸ƒ:{Style.RESET_ALL}")
            print(f"  ğŸš« JSONè§£æé”™è¯¯: {Fore.RED}{stats['parse_errors']}{Style.RESET_ALL}")
            print(f"  ğŸ“ å­—æ®µç¼ºå¤±é”™è¯¯: {Fore.YELLOW}{stats['field_errors']}{Style.RESET_ALL}")
            print(f"  ğŸ”„ ç±»å‹é”™è¯¯:     {Fore.ORANGE}{stats['type_errors']}{Style.RESET_ALL}")
            print(f"  ğŸ“Š èŒƒå›´é”™è¯¯:     {Fore.MAGENTA}{stats['range_errors']}{Style.RESET_ALL}")
    
    def _print_cost_summary(self):
        """æ‰“å°æˆæœ¬ç»Ÿè®¡æ‘˜è¦"""
        stats = self.cost_analyzer.cost_stats
        
        print(f"\n{Fore.YELLOW}ğŸ’° æˆæœ¬åˆ†æç»Ÿè®¡:{Style.RESET_ALL}")
        print(f"  ğŸ–¼ï¸  åˆ†æå›¾ç‰‡æ•°:   {Fore.GREEN}{stats['successful_analyses']}{Style.RESET_ALL}")
        print(f"  ğŸ”¤ æ€»è¾“å…¥Token:  {Fore.BLUE}{stats['total_prompt_tokens']:,}{Style.RESET_ALL}")
        print(f"  ğŸ“ æ€»è¾“å‡ºToken:  {Fore.BLUE}{stats['total_completion_tokens']:,}{Style.RESET_ALL}")
        
        if stats['total_reasoning_tokens'] > 0:
            print(f"  ï¿½ï¿½ æ¨ç†Token:    {Fore.MAGENTA}{stats['total_reasoning_tokens']:,}{Style.RESET_ALL}")
        
        print(f"  ğŸ’µ æ€»æˆæœ¬:       {Fore.RED}Â¥{stats['total_cost']:.4f}{Style.RESET_ALL}")
        
        if stats['successful_analyses'] > 0:
            print(f"  ğŸ“· å¹³å‡å•å¼ æˆæœ¬: {Fore.CYAN}Â¥{stats['average_cost_per_image']:.4f}{Style.RESET_ALL}")
    
    def _print_detailed_stats(self):
        """æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        distribution_stats = self.cost_analyzer.get_cost_distribution_stats()
        
        if not distribution_stats:
            return
        
        print(f"\n{Fore.YELLOW}ğŸ“ˆ è¯¦ç»†ç»Ÿè®¡åˆ†æ:{Style.RESET_ALL}")
        
        # æˆæœ¬åˆ†å¸ƒ
        cost_stats = distribution_stats['cost_stats']
        print(f"  ğŸ’¸ æˆæœ¬åˆ†å¸ƒ:")
        print(f"    æœ€ä½: {Fore.GREEN}Â¥{cost_stats['min_cost']:.4f}{Style.RESET_ALL}")
        print(f"    æœ€é«˜: {Fore.RED}Â¥{cost_stats['max_cost']:.4f}{Style.RESET_ALL}")
        print(f"    ä¸­ä½: {Fore.CYAN}Â¥{cost_stats['median_cost']:.4f}{Style.RESET_ALL}")
        
        # æ‰“å°æ–°çš„è´¨é‡åˆ†å¸ƒè¯¦æƒ…è¡¨
        self._print_quality_distribution_table()
        
        # AIç”Ÿæˆç»Ÿè®¡
        ai_stats = distribution_stats['ai_detection_stats']
        print(f"  ğŸ¤– AIç”Ÿæˆæ£€æµ‹ (å…¨å±€):")
        print(f"    AIç”Ÿæˆ: {Fore.YELLOW}{ai_stats['ai_generated_count']}{Style.RESET_ALL} / {self.cost_analyzer.cost_stats['successful_analyses']} ({ai_stats['ai_generated_ratio']:.1f}%)")
        
        # æ°´å°ç»Ÿè®¡
        watermark_stats = distribution_stats['watermark_stats']
        print(f"  ğŸ’§ æ°´å°æ£€æµ‹ (å…¨å±€):")
        print(f"    å«æ°´å°: {Fore.BLUE}{watermark_stats['watermark_count']}{Style.RESET_ALL} / {self.cost_analyzer.cost_stats['successful_analyses']} ({watermark_stats['watermark_ratio']:.1f}%)")
    
    def _print_quality_distribution_table(self):
        """æ‰“å°æ ¼å¼åŒ–çš„è´¨é‡åˆ†å¸ƒè¡¨æ ¼"""
        table_data = self.cost_analyzer.get_quality_distribution_data()
        
        if not table_data:
            return
            
        print(f"\n  â­ {Fore.CYAN}è´¨é‡åˆ†å¸ƒè¯¦æƒ…:{Style.RESET_ALL}")
        
        # è¡¨å¤´
        header = f"  {'åˆ†æ•°åŒºé—´':<18} | {'å›¾ç‰‡æ•°é‡':>8} | {'å æ¯”':>7} | {'AIç”Ÿæˆ':>6} | {'åŒºé—´AIç‡':>9} | {'å«æ°´å°':>7} | {'åŒºé—´æ°´å°ç‡':>11} "
        print(f"  {Fore.WHITE}{Style.BRIGHT}{header}{Style.RESET_ALL}")
        print(f"  {'-'*len(header)}")

        # è¡¨å†…å®¹
        for row in table_data:
            line = (
                f"  {row['quality_range']:<18} | "
                f"{row['count']:>8,} | "
                f"{row['percentage']:>6.1f}% | "
                f"{row['ai_count']:>6,} | "
                f"{row['ai_rate']:>8.1f}% | "
                f"{row['watermark_count']:>7,} | "
                f"{row['watermark_rate']:>10.1f}% "
            )
            print(line)

    def _print_detailed_errors(self):
        """æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯"""
        print(f"\n{Fore.RED}ğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:{Style.RESET_ALL}")
        print("-" * 60)
        
        for error_info in self.validator.detailed_errors[:10]:  # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
            file_name = os.path.basename(error_info['file_path'])
            print(f"\n{Fore.YELLOW}ğŸ“„ {file_name}:{Style.RESET_ALL}")
            
            for error in error_info['errors']:
                print(f"  {Fore.RED}âŒ{Style.RESET_ALL} {error}")
            
            for warning in error_info['warnings']:
                print(f"  {Fore.ORANGE}âš ï¸{Style.RESET_ALL} {warning}")
        
        if len(self.validator.detailed_errors) > 10:
            remaining = len(self.validator.detailed_errors) - 10
            print(f"\n{Fore.YELLOW}... è¿˜æœ‰ {remaining} ä¸ªé”™è¯¯æœªæ˜¾ç¤º{Style.RESET_ALL}")
    
    def export_csv(self, output_path: str):
        """å¯¼å‡ºè¯¦ç»†åˆ†æç»“æœä¸ºCSVæ–‡ä»¶"""
        if not self.cost_analyzer.detailed_costs:
            print(f"{Fore.YELLOW}âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„æˆæœ¬æ•°æ®å¯å¯¼å‡º{Style.RESET_ALL}")
            return
        
        try:
            df = pd.DataFrame(self.cost_analyzer.detailed_costs)
            df.to_csv(output_path, index=False, encoding='utf-8')
            print(f"{Fore.GREEN}âœ… CSVæŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_path}{Style.RESET_ALL}")
        except Exception as e:
            print(f"{Fore.RED}âŒ CSVå¯¼å‡ºå¤±è´¥: {str(e)}{Style.RESET_ALL}")
    
    def generate_html_report(self, output_path: str):
        """ç”ŸæˆHTMLæ ¼å¼æŠ¥å‘Š"""
        try:
            html_content = self._build_html_content()
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            print(f"{Fore.GREEN}âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}{Style.RESET_ALL}")
        except Exception as e:
            print(f"{Fore.RED}âŒ HTMLæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}{Style.RESET_ALL}")
    
    def _build_html_content(self) -> str:
        """æ„å»ºHTMLæŠ¥å‘Šå†…å®¹"""
        stats = self.validator.validation_stats
        cost_stats = self.cost_analyzer.cost_stats
        distribution_stats = self.cost_analyzer.get_cost_distribution_stats()
        
        html = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å›¾åƒè´¨é‡åˆ†ææŠ¥å‘Š</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .header {{ text-align: center; color: #333; border-bottom: 2px solid #4CAF50; padding-bottom: 20px; }}
        .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }}
        .stat-card {{ background: #f8f9fa; padding: 20px; border-radius: 8px; border-left: 4px solid #4CAF50; }}
        .stat-title {{ font-weight: bold; color: #333; margin-bottom: 10px; }}
        .stat-value {{ font-size: 1.2em; color: #2196F3; }}
        .error-section {{ background: #fff3cd; padding: 15px; border-radius: 8px; border-left: 4px solid #ffc107; margin: 20px 0; }}
        .cost-section {{ background: #d1ecf1; padding: 15px; border-radius: 8px; border-left: 4px solid #17a2b8; margin: 20px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ–¼ï¸ å›¾åƒè´¨é‡åˆ†ææŠ¥å‘Š</h1>
            <p>ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-title">ğŸ“ æ–‡ä»¶éªŒè¯ç»Ÿè®¡</div>
                <div class="stat-value">æ€»æ–‡ä»¶: {stats['total_files']}</div>
                <div class="stat-value">æœ‰æ•ˆæ–‡ä»¶: {stats['valid_files']}</div>
                <div class="stat-value">æ— æ•ˆæ–‡ä»¶: {stats['invalid_files']}</div>
                <div class="stat-value">æˆåŠŸç‡: {(stats['valid_files']/stats['total_files']*100) if stats['total_files']>0 else 0:.1f}%</div>
            </div>
            
            <div class="stat-card">
                <div class="stat-title">ğŸ’° æˆæœ¬ç»Ÿè®¡</div>
                <div class="stat-value">åˆ†æå›¾ç‰‡: {cost_stats['successful_analyses']}</div>
                <div class="stat-value">æ€»Token: {cost_stats['total_tokens']:,}</div>
                <div class="stat-value">æ€»æˆæœ¬: Â¥{cost_stats['total_cost']:.4f}</div>
                <div class="stat-value">å¹³å‡æˆæœ¬: Â¥{cost_stats['average_cost_per_image']:.4f}</div>
            </div>
        """
        
        if distribution_stats:
            score_stats = distribution_stats['score_stats']
            ai_stats = distribution_stats['ai_detection_stats']
            html += f"""
            <div class="stat-card">
                <div class="stat-title">â­ è´¨é‡åˆ†æ</div>
                <div class="stat-value">å¹³å‡åˆ†: {score_stats['average_score']:.1f}</div>
                <div class="stat-value">æœ€é«˜åˆ†: {score_stats['max_score']:.1f}</div>
                <div class="stat-value">æœ€ä½åˆ†: {score_stats['min_score']:.1f}</div>
                <div class="stat-value">AIç”Ÿæˆ: {ai_stats['ai_generated_ratio']:.1f}%</div>
            </div>
            """
        
        html += """
        </div>
    </div>
</body>
</html>
        """
        
        return html


def find_result_files(root_dir: str, extensions: Tuple[str, ...] = ('.json',)) -> List[str]:
    """
    é€’å½’æŸ¥æ‰¾ç»“æœJSONæ–‡ä»¶
    
    Args:
        root_dir: æœç´¢æ ¹ç›®å½•
        extensions: æ–‡ä»¶æ‰©å±•åå…ƒç»„
        
    Returns:
        æ‰¾åˆ°çš„JSONæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    all_files = []
    for ext in extensions:
        pattern = os.path.join(root_dir, '**', f'*{ext}')
        all_files.extend(glob.glob(pattern, recursive=True))
    
    return sorted(list(set(all_files)))  # å»é‡å¹¶æ’åº 

def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œå…¥å£å’Œä¸»æµç¨‹æ§åˆ¶"""
    parser = argparse.ArgumentParser(
        description='åˆ†ævlm_score.pyç”Ÿæˆçš„JSONç»“æœæ–‡ä»¶ï¼ŒéªŒè¯æ ¼å¼å¹¶ç»Ÿè®¡æˆæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python result_analyzer.py /path/to/results          # åŸºæœ¬åˆ†æ
  python result_analyzer.py /path/to/results --verbose # è¯¦ç»†æ¨¡å¼
  python result_analyzer.py /path/to/results --export-csv analysis.csv
  python result_analyzer.py /path/to/results --export-html report.html
  python result_analyzer.py /path/to/results --output-format all --export-path ./reports/
        """
    )
    
    # ä½ç½®å‚æ•°
    parser.add_argument(
        'results_directory',
        help='åŒ…å«JSONç»“æœæ–‡ä»¶çš„ç›®å½•è·¯å¾„'
    )
    
    # å¯é€‰å‚æ•°
    parser.add_argument(
        '--output-format',
        choices=['console', 'csv', 'html', 'all'],
        default='console',
        help='è¾“å‡ºæ ¼å¼ (é»˜è®¤: console)'
    )
    
    parser.add_argument(
        '--export-path',
        help='å¯¼å‡ºæ–‡ä»¶è·¯å¾„ (ç”¨äºCSV/HTMLè¾“å‡º)'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='è¯¦ç»†æ¨¡å¼ï¼Œæ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶çš„éªŒè¯ç»“æœ'
    )
    
    parser.add_argument(
        '--export-csv',
        help='å¯¼å‡ºCSVæ–‡ä»¶çš„è·¯å¾„'
    )
    
    parser.add_argument(
        '--export-html',
        help='å¯¼å‡ºHTMLæŠ¥å‘Šçš„è·¯å¾„'
    )
    
    parser.add_argument(
        '--filter-valid',
        action='store_true',
        help='åªåˆ†ææœ‰æ•ˆçš„JSONæ–‡ä»¶'
    )
    
    args = parser.parse_args()
    
    try:
        # éªŒè¯è¾“å…¥ç›®å½•
        if not os.path.exists(args.results_directory):
            print(f"{Fore.RED}âŒ é”™è¯¯: ç›®å½•ä¸å­˜åœ¨: {args.results_directory}{Style.RESET_ALL}")
            return 1
        
        if not os.path.isdir(args.results_directory):
            print(f"{Fore.RED}âŒ é”™è¯¯: æŒ‡å®šè·¯å¾„ä¸æ˜¯ç›®å½•: {args.results_directory}{Style.RESET_ALL}")
            return 1
        
        # æŸ¥æ‰¾JSONæ–‡ä»¶
        print(f"{Fore.CYAN}ğŸ” æ­£åœ¨æ‰«æç›®å½•: {args.results_directory}{Style.RESET_ALL}")
        json_files = find_result_files(args.results_directory)
        
        if not json_files:
            print(f"{Fore.YELLOW}âš ï¸ åœ¨æŒ‡å®šç›®å½•ä¸­æœªæ‰¾åˆ°JSONæ–‡ä»¶{Style.RESET_ALL}")
            return 0
        
        print(f"{Fore.GREEN}ğŸ“ æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶{Style.RESET_ALL}")
        
        # åˆå§‹åŒ–åˆ†æå™¨
        validator = JsonValidator()
        cost_analyzer = CostAnalyzer()
        report_generator = ReportGenerator(validator, cost_analyzer)
        
        # éªŒè¯æ‰€æœ‰æ–‡ä»¶
        print(f"{Fore.YELLOW}ğŸ”„ å¼€å§‹éªŒè¯æ–‡ä»¶...{Style.RESET_ALL}")
        validation_results = []
        
        for json_file in json_files:
            if args.verbose:
                print(f"  éªŒè¯: {os.path.basename(json_file)}", end=" ... ")
            
            result = validator.validate_single_file(json_file)
            validation_results.append(result)
            
            if args.verbose:
                status = f"{Fore.GREEN}âœ“{Style.RESET_ALL}" if result['is_valid'] else f"{Fore.RED}âœ—{Style.RESET_ALL}"
                print(status)
        
        # è¿‡æ»¤ç»“æœ (å¦‚æœæŒ‡å®š)
        if args.filter_valid:
            validation_results = [r for r in validation_results if r['is_valid']]
            print(f"{Fore.BLUE}ğŸ“‹ å·²è¿‡æ»¤ï¼Œä»…åˆ†æ {len(validation_results)} ä¸ªæœ‰æ•ˆæ–‡ä»¶{Style.RESET_ALL}")
        
        # åˆ†ææˆæœ¬
        print(f"{Fore.YELLOW}ğŸ’° åˆ†ææˆæœ¬ä¿¡æ¯...{Style.RESET_ALL}")
        cost_analyzer.analyze_costs(validation_results)
        
        # ç”ŸæˆæŠ¥å‘Š
        if args.output_format in ['console', 'all']:
            report_generator.print_console_report(verbose=args.verbose)
        
        # å¯¼å‡ºCSV
        if args.export_csv or args.output_format in ['csv', 'all']:
            csv_path = args.export_csv
            if not csv_path:
                if args.export_path:
                    csv_path = os.path.join(args.export_path, 'analysis_results.csv')
                else:
                    csv_path = 'analysis_results.csv'
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(csv_path) if os.path.dirname(csv_path) else '.', exist_ok=True)
            report_generator.export_csv(csv_path)
        
        # å¯¼å‡ºHTML
        if args.export_html or args.output_format in ['html', 'all']:
            html_path = args.export_html
            if not html_path:
                if args.export_path:
                    html_path = os.path.join(args.export_path, 'analysis_report.html')
                else:
                    html_path = 'analysis_report.html'
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(html_path) if os.path.dirname(html_path) else '.', exist_ok=True)
            report_generator.generate_html_report(html_path)
        
        # æœ€ç»ˆæç¤º
        print(f"\n{Fore.GREEN}âœ… åˆ†æå®Œæˆï¼{Style.RESET_ALL}")
        
        # å¦‚æœæœ‰é”™è¯¯ï¼Œå»ºè®®ç”¨æˆ·æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
        if validator.validation_stats['invalid_files'] > 0:
            print(f"{Fore.YELLOW}ğŸ’¡ æç¤º: ä½¿ç”¨ --verbose å‚æ•°æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯{Style.RESET_ALL}")
        
        return 0
        
    except KeyboardInterrupt:
        print(f"\n{Fore.YELLOW}âš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ{Style.RESET_ALL}")
        return 130
    except Exception as e:
        print(f"{Fore.RED}âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}{Style.RESET_ALL}")
        if args.verbose:
            print(f"{Fore.RED}è¯¦ç»†é”™è¯¯ä¿¡æ¯:{Style.RESET_ALL}")
            print(traceback.format_exc())
        return 1


if __name__ == "__main__":
    """ç¨‹åºå…¥å£ç‚¹"""
    try:
        exit_code = main()
        exit(exit_code)
    except Exception as e:
        print(f"{Fore.RED}âŒ è‡´å‘½é”™è¯¯: {str(e)}{Style.RESET_ALL}")
        print(traceback.format_exc())
        exit(1) 