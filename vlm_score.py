import os
import glob
import json
import re
import argparse
import base64
import asyncio
import aiohttp
import aiofiles
from tqdm.asyncio import tqdm
import xmltodict
import traceback
from dotenv import load_dotenv
import filetype
from colorama import init, Fore, Style
import time

# åˆå§‹åŒ–coloramaç”¨äºå½©è‰²è¾“å‡º
init(autoreset=True)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def validate_config():
    """éªŒè¯å¿…éœ€çš„ç¯å¢ƒå˜é‡é…ç½®"""
    required_vars = ['VLM_API_ENDPOINT', 'VLM_API_TOKEN', 'VLM_MODEL_NAME']
    missing_vars = []
    
    for var in required_vars:
        if not os.getenv(var):
            missing_vars.append(var)
    
    if missing_vars:
        raise ValueError(f"ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}ã€‚è¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®ã€‚")
    
    # æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆæ©ç æ•æ„Ÿä¿¡æ¯ï¼‰
    token = os.getenv('VLM_API_TOKEN', '')
    masked_token = token[:8] + '*' * (len(token) - 12) + token[-4:] if len(token) > 12 else '***'
    
    print(f"{Fore.GREEN}âœ“ é…ç½®åŠ è½½å®Œæˆ:{Style.RESET_ALL}")
    print(f"  ğŸŒ APIç«¯ç‚¹: {Fore.CYAN}{os.getenv('VLM_API_ENDPOINT')}{Style.RESET_ALL}")
    print(f"  ğŸ”‘ APIä»¤ç‰Œ: {Fore.YELLOW}{masked_token}{Style.RESET_ALL}")
    print(f"  ğŸ¤– æ¨¡å‹åç§°: {Fore.MAGENTA}{os.getenv('VLM_MODEL_NAME')}{Style.RESET_ALL}")
    print(f"  ğŸš€ å¹¶å‘æ•°é‡: {Fore.BLUE}{os.getenv('CONCURRENT_LIMIT', '3')}{Style.RESET_ALL}")

# éªŒè¯é…ç½®
validate_config()

# ç”¨æˆ·å®šä¹‰çš„æç¤ºè¯æ¨¡æ¿ï¼ˆå¢å¼ºXMLè¾“å‡ºæ ¼å¼ï¼‰
USER_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾ç‰‡è´¨é‡è¯„ä¼°ä¸“å®¶ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
1. **å›¾åƒæ¥æºåˆ†æ**ï¼š
   - **AIç”Ÿæˆæ£€æµ‹**ï¼šæ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨ä»¥ä¸‹ç‰¹å¾ï¼ˆä»»ä¸€å³å¯åˆ¤å®šä¸ºAIç”Ÿæˆï¼‰ï¼š
     - è¿‡åº¦å¹³æ»‘çš„çº¹ç†ï¼ˆå¦‚çš®è‚¤æ— æ¯›å­”ã€æ¤è¢«æ— ç»†èŠ‚ï¼‰ã€‚
     - ä¸è‡ªç„¶çš„å…‰å½±ï¼ˆå¦‚å…‰æºæ–¹å‘çŸ›ç›¾ã€é˜´å½±ä¸ç¬¦åˆç‰©ç†è§„å¾‹ï¼‰ã€‚
     - å¼‚å¸¸å®Œç¾çš„æ„å›¾ï¼ˆå¦‚å®Œå…¨å¯¹ç§°ä¸”æ— æ‹æ‘„æŠ–åŠ¨ç—•è¿¹ï¼‰ã€‚
     - éç°å®å…ƒç´ ï¼ˆå¦‚äººç‰©æ‰‹æŒ‡æ•°é‡å¼‚å¸¸ã€ç‰©ä½“æ¯”ä¾‹å¤±çœŸï¼‰ã€‚
   - **çœŸå®ç…§ç‰‡ç‰¹å¾**ï¼šåˆ¤æ–­æ˜¯å¦ç¬¦åˆçœŸå®æ‹æ‘„æ¡ä»¶ï¼ˆå¦‚å­˜åœ¨å™ªç‚¹ã€è½»å¾®æ¨¡ç³Šã€è‡ªç„¶æ™¯æ·±ï¼‰ã€‚

2. **æ°´å°æ£€æµ‹**ï¼š
   - åˆ†æå…¨å›¾æ˜¯å¦å­˜åœ¨å¯è§æ°´å°ï¼ˆå¦‚å“ç‰ŒLOGOã€ç‰ˆæƒæ–‡å­—ï¼‰ï¼Œæè¿°ä½ç½®å’Œæ˜¾è‘—æ€§ã€‚

3. **è´¨é‡è¯„åˆ†ç»´åº¦**ï¼š
   - **æ¸…æ™°åº¦**ï¼šåˆ†è¾¨ç‡æ˜¯å¦è¶³å¤Ÿï¼Œæ˜¯å¦å­˜åœ¨æ¨¡ç³Šæˆ–å‹ç¼©ä¼ªå½±ã€‚
   - **æ„å›¾**ï¼šç”»é¢å¸ƒå±€æ˜¯å¦ç¾è§‚ï¼Œä¸»ä½“æ˜¯å¦çªå‡ºã€‚
   - **è‰²å½©**ï¼šè‰²è°ƒæ˜¯å¦è‡ªç„¶ï¼Œæ˜¯å¦å­˜åœ¨è¿‡æ›æˆ–æ¬ æ›ã€‚
   - **å†…å®¹ç›¸å…³æ€§**ï¼šå›¾ç‰‡å†…å®¹æ˜¯å¦ç¬¦åˆç°å®é€»è¾‘ï¼ˆå¦‚äººç‰©è¡¨æƒ…è‡ªç„¶ã€åœºæ™¯æ— å¼‚å¸¸ï¼‰ã€‚

4. **ç»¼åˆè¯„åˆ†è§„åˆ™**ï¼š
   - **åŸºç¡€åˆ†**ï¼šæŒ‰æƒé‡è®¡ç®—æ€»åˆ†ï¼ˆæ¸…æ™°åº¦40%ï¼Œæ„å›¾30%ï¼Œè‰²å½©20%ï¼Œå†…å®¹10%ï¼‰ã€‚
   - **AIç”Ÿæˆæƒ©ç½š**ï¼šè‹¥æ£€æµ‹ä¸ºAIç”Ÿæˆï¼Œæ€»åˆ†ç›´æ¥æ‰£é™¤ **2.0åˆ†**ï¼ˆæœ€ä½åˆ†ä¿ç•™0åˆ†ï¼‰ã€‚
   - **æœ€ç»ˆç­‰çº§**ï¼š
     - â‰¥8.5ï¼šé«˜è´¨é‡ï¼ˆçœŸå®ç…§ç‰‡ä¸”æ— æ˜æ˜¾ç¼ºé™·ï¼‰ã€‚
     - 7.0-8.4ï¼šä¸­ç­‰è´¨é‡ï¼ˆçœŸå®ç…§ç‰‡ä½†æœ‰è½»å¾®ç¼ºé™·ï¼‰ã€‚
     - <7.0ï¼šä½è´¨é‡ï¼ˆAIç”Ÿæˆæˆ–ä¸¥é‡ç¼ºé™·ï¼‰ã€‚

5. **è¾“å‡ºè§„èŒƒ**ï¼š
   - é¦–å…ˆç”¨è‡ªç„¶è¯­è¨€è¯¦ç»†åˆ†æå›¾ç‰‡è´¨é‡å„ä¸ªç»´åº¦
   - æœ€åå¿…é¡»è¾“å‡ºçº¯å‡€çš„XMLæ ¼å¼ç»“æœï¼Œä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼ï¼š

<result>
<is_ai_generated>trueæˆ–false</is_ai_generated>
<watermark_present>trueæˆ–false</watermark_present>
<watermark_location>æ°´å°ä½ç½®æè¿°æˆ–æ— </watermark_location>
<score>æ•°å­—å¾—åˆ†</score>
<feedback>ç®€è¦è¯„åˆ†ç†ç”±</feedback>
</result>

é‡è¦ï¼šXMLéƒ¨åˆ†å¿…é¡»æ˜¯çº¯å‡€æ ¼å¼ï¼Œä¸è¦ç”¨markdownä»£ç å—åŒ…è£…ï¼Œä¸è¦æœ‰é¢å¤–çš„æ ¼å¼åŒ–ç¬¦å·ã€‚
"""

class CostCalculator:
    """APIæˆæœ¬è®¡ç®—å™¨"""
    
    def __init__(self):
        # è±†åŒ…æ¨¡å‹å®šä»·ï¼ˆå…ƒ/ç™¾ä¸‡tokenï¼‰
        self.input_price = 0.15  # è¾“å…¥tokenä»·æ ¼
        self.output_price = 1.50  # è¾“å‡ºtokenä»·æ ¼
        
        # ç»Ÿè®¡æ•°æ®
        self.total_prompt_tokens = 0
        self.total_completion_tokens = 0
        self.total_reasoning_tokens = 0
        self.total_requests = 0
        self.successful_requests = 0
        
    def add_usage(self, api_usage):
        """æ·»åŠ APIä½¿ç”¨ç»Ÿè®¡"""
        if not api_usage:
            return
            
        self.total_requests += 1
        self.successful_requests += 1
        
        # åŸºç¡€tokenç»Ÿè®¡
        self.total_prompt_tokens += api_usage.get('prompt_tokens', 0)
        self.total_completion_tokens += api_usage.get('completion_tokens', 0)
        
        # reasoning_tokensç»Ÿè®¡ï¼ˆå±äºè¾“å‡ºtokenï¼‰
        completion_details = api_usage.get('completion_tokens_details', {})
        reasoning_tokens = completion_details.get('reasoning_tokens', 0)
        self.total_reasoning_tokens += reasoning_tokens
    
    def calculate_cost(self):
        """è®¡ç®—æ€»è´¹ç”¨ï¼ˆäººæ°‘å¸ï¼‰"""
        # è¾“å…¥æˆæœ¬
        input_cost = (self.total_prompt_tokens / 1_000_000) * self.input_price
        
        # è¾“å‡ºæˆæœ¬ï¼ˆåŒ…å«reasoning_tokensï¼‰
        total_output_tokens = self.total_completion_tokens + self.total_reasoning_tokens
        output_cost = (total_output_tokens / 1_000_000) * self.output_price
        
        total_cost = input_cost + output_cost
        
        return {
            'input_tokens': self.total_prompt_tokens,
            'output_tokens': self.total_completion_tokens,
            'reasoning_tokens': self.total_reasoning_tokens,
            'total_output_tokens': total_output_tokens,
            'input_cost': input_cost,
            'output_cost': output_cost,
            'total_cost': total_cost,
            'total_requests': self.total_requests,
            'successful_requests': self.successful_requests
        }
    
    def format_cost_report(self, processing_time=0, image_count=0):
        """æ ¼å¼åŒ–æˆæœ¬æŠ¥å‘Š"""
        cost_data = self.calculate_cost()
        
        report = f"\n{Fore.CYAN}ğŸ’° æˆæœ¬åˆ†ææŠ¥å‘Š:{Style.RESET_ALL}\n"
        report += f"{'='*50}\n"
        
        # Tokenä½¿ç”¨ç»Ÿè®¡
        report += f"{Fore.YELLOW}ğŸ“Š Tokenä½¿ç”¨ç»Ÿè®¡:{Style.RESET_ALL}\n"
        report += f"  ğŸ”¤ è¾“å…¥Token:     {Fore.GREEN}{cost_data['input_tokens']:,}{Style.RESET_ALL}\n"
        report += f"  ğŸ“ è¾“å‡ºToken:     {Fore.GREEN}{cost_data['output_tokens']:,}{Style.RESET_ALL}\n"
        if cost_data['reasoning_tokens'] > 0:
            report += f"  ğŸ§  æ¨ç†Token:     {Fore.BLUE}{cost_data['reasoning_tokens']:,}{Style.RESET_ALL}\n"
        report += f"  ğŸ“Š æ€»è¾“å‡ºToken:   {Fore.MAGENTA}{cost_data['total_output_tokens']:,}{Style.RESET_ALL}\n"
        
        # è´¹ç”¨è®¡ç®—
        report += f"\n{Fore.YELLOW}ğŸ’³ è´¹ç”¨è®¡ç®—:{Style.RESET_ALL}\n"
        report += f"  ğŸ’µ è¾“å…¥è´¹ç”¨:     {Fore.GREEN}Â¥{cost_data['input_cost']:.4f}{Style.RESET_ALL}\n"
        report += f"  ğŸ’µ è¾“å‡ºè´¹ç”¨:     {Fore.GREEN}Â¥{cost_data['output_cost']:.4f}{Style.RESET_ALL}\n"
        report += f"  ğŸ’° æ€»è´¹ç”¨:       {Fore.RED}Â¥{cost_data['total_cost']:.4f}{Style.RESET_ALL}\n"
        
        # å¹³å‡æˆæœ¬
        if image_count > 0:
            avg_cost = cost_data['total_cost'] / image_count
            report += f"  ğŸ“· å•å¼ å›¾ç‰‡æˆæœ¬: {Fore.CYAN}Â¥{avg_cost:.4f}{Style.RESET_ALL}\n"
        
        # è¯·æ±‚ç»Ÿè®¡
        report += f"\n{Fore.YELLOW}ğŸ“ˆ è¯·æ±‚ç»Ÿè®¡:{Style.RESET_ALL}\n"
        report += f"  âœ… æˆåŠŸè¯·æ±‚:     {Fore.GREEN}{cost_data['successful_requests']}{Style.RESET_ALL}\n"
        report += f"  ğŸ“Š æ€»è¯·æ±‚æ•°:     {Fore.BLUE}{cost_data['total_requests']}{Style.RESET_ALL}\n"
        
        # æ•ˆç‡ç»Ÿè®¡
        if processing_time > 0:
            cost_per_second = cost_data['total_cost'] / processing_time
            report += f"  â±ï¸  æ¯ç§’æˆæœ¬:     {Fore.MAGENTA}Â¥{cost_per_second:.6f}{Style.RESET_ALL}\n"
        
        report += f"{'='*50}\n"
        
        return report, cost_data

class ImageQualityAnalyzer:
    def __init__(self, model_name=None, concurrent_limit=None):
        """åˆå§‹åŒ–å¼‚æ­¥APIå®¢æˆ·ç«¯ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®"""
        self.api_endpoint = os.getenv('VLM_API_ENDPOINT')
        self.api_token = os.getenv('VLM_API_TOKEN')
        self.model_name = model_name or os.getenv('VLM_MODEL_NAME')
        self.max_tokens = int(os.getenv('VLM_MAX_TOKENS', '16384'))
        self.temperature = float(os.getenv('VLM_TEMPERATURE', '0.3'))
        self.timeout = int(os.getenv('VLM_TIMEOUT', '180'))
        self.concurrent_limit = concurrent_limit or int(os.getenv('CONCURRENT_LIMIT', '3'))
        
        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘
        self.semaphore = asyncio.Semaphore(self.concurrent_limit)
        
        # æ„å»ºè¯·æ±‚å¤´ï¼ŒåŒ…å«è®¤è¯ä¿¡æ¯
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_token}"
        }
    
    async def _image_to_base64(self, image_path):
        """å¼‚æ­¥å°†å›¾ç‰‡è½¬æ¢ä¸ºBase64ç¼–ç """
        async with aiofiles.open(image_path, "rb") as img_file:
            content = await img_file.read()
            return base64.b64encode(content).decode('utf-8')
    
    def _build_payload(self, base64_image, img_type):
        """æ„å»ºAPIè¯·æ±‚è´Ÿè½½ï¼Œé€‚é…Volces APIæ ¼å¼"""
        return {
            "model": self.model_name,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": USER_PROMPT
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{img_type};base64,{base64_image}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": self.max_tokens,
            "temperature": self.temperature
        }

    def _extract_xml(self, text):
        """ä»æ¨¡å‹è¾“å‡ºä¸­æå–XMLå†…å®¹ï¼ˆå¢å¼ºé²æ£’æ€§ï¼‰"""
        try:
            # ç­–ç•¥1: æå–<result>æ ‡ç­¾å—ï¼ˆæœ€å¸¸è§ï¼‰
            xml_patterns = [
                r'<result[^>]*>(.*?)</result>',  # æ ‡å‡†resultæ ‡ç­¾
                r'```xml\s*<result[^>]*>(.*?)</result>\s*```',  # markdownåŒ…è£…çš„XML
                r'```\s*<result[^>]*>(.*?)</result>\s*```',  # æ— xmlæ ‡è¯†çš„ä»£ç å—
                r'<result[^>]*>(.*?)(?=\n\n|\Z)',  # ä¸å®Œæ•´çš„resultæ ‡ç­¾
            ]
            
            xml_content = None
            for pattern in xml_patterns:
                match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
                if match:
                    xml_content = f"<result>{match.group(1)}</result>"
                    break
            
            # ç­–ç•¥2: å¦‚æœæ‰¾ä¸åˆ°resultæ ‡ç­¾ï¼Œå°è¯•æå–ç‹¬ç«‹çš„XMLå­—æ®µ
            if not xml_content:
                xml_fields = {}
                field_patterns = {
                    'is_ai_generated': r'<is_ai_generated[^>]*>(.*?)</is_ai_generated>',
                    'watermark_present': r'<watermark_present[^>]*>(.*?)</watermark_present>',
                    'watermark_location': r'<watermark_location[^>]*>(.*?)</watermark_location>',
                    'score': r'<score[^>]*>(.*?)</score>',
                    'feedback': r'<feedback[^>]*>(.*?)</feedback>'
                }
                
                for field, pattern in field_patterns.items():
                    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
                    if match:
                        xml_fields[field] = match.group(1).strip()
                
                if xml_fields:
                    # é‡å»ºXML
                    xml_parts = ['<result>']
                    for field, value in xml_fields.items():
                        xml_parts.append(f'<{field}>{value}</{field}>')
                    xml_parts.append('</result>')
                    xml_content = ''.join(xml_parts)
            
            if not xml_content:
                return {
                    "error": "XML_NOT_FOUND",
                    "raw_output": text[:500] + "..." if len(text) > 500 else text
                }
            
            # æ¸…ç†XMLå†…å®¹
            xml_content = re.sub(r'```xml\s*', '', xml_content)
            xml_content = re.sub(r'\s*```', '', xml_content)
            xml_content = xml_content.strip()
            
            # è§£æXML
            try:
                result_dict = xmltodict.parse(xml_content, dict_constructor=dict)['result']
            except Exception as parse_error:
                # å¦‚æœxmltodictå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨è§£æ
                manual_result = {}
                for field in ['is_ai_generated', 'watermark_present', 'watermark_location', 'score', 'feedback']:
                    pattern = f'<{field}[^>]*>(.*?)</{field}>'
                    match = re.search(pattern, xml_content, re.DOTALL | re.IGNORECASE)
                    if match:
                        manual_result[field] = match.group(1).strip()
                
                if manual_result:
                    result_dict = manual_result
                else:
                    raise parse_error
            
            # ç±»å‹è½¬æ¢å’ŒéªŒè¯
            processed = {}
            for key, value in result_dict.items():
                key = key.lower().strip()
                if key in ['is_ai_generated', 'watermark_present']:
                    processed[key] = str(value).lower() in ['true', 'yes', '1', 'True']
                elif key == 'score':
                    try:
                        if isinstance(value, str):
                            # æå–æ•°å­—
                            num_match = re.search(r'(\d+\.?\d*)', value)
                            processed[key] = round(float(num_match.group(1)), 1) if num_match else 0.0
                        else:
                            processed[key] = round(float(value), 1)
                        # ç¡®ä¿åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…
                        processed[key] = max(0.0, min(10.0, processed[key]))
                    except:
                        processed[key] = 0.0
                else:
                    processed[key] = str(value).strip() if value else ''
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
            required_fields = {
                'is_ai_generated': False,
                'watermark_present': False,
                'watermark_location': 'æ— ',
                'score': 0.0,
                'feedback': 'è§£ææˆåŠŸ'
            }
            
            for field, default_value in required_fields.items():
                if field not in processed:
                    processed[field] = default_value
            
            return processed
            
        except Exception as e:
            return {
                "error": f"XML_PARSING_ERROR: {str(e)}",
                "raw_output": text[:500] + "..." if len(text) > 500 else text,
                "traceback": traceback.format_exc()
            }

    async def analyze_image(self, session, image_path):
        """é€šè¿‡VLM APIå¼‚æ­¥åˆ†æå•å¼ å›¾ç‰‡"""
        async with self.semaphore:  # æ§åˆ¶å¹¶å‘æ•°é‡
            try:
                # å¼‚æ­¥è¯»å–å’Œç¼–ç å›¾ç‰‡
                base64_image = await self._image_to_base64(image_path)
                
                # æ£€æµ‹å›¾ç‰‡ç±»å‹
                img_type = 'jpeg'  # é»˜è®¤
                try:
                    kind = filetype.guess(image_path)
                    if kind and kind.mime.startswith('image/'):
                        img_type = kind.extension
                        if img_type == 'jpg':
                            img_type = 'jpeg'
                except Exception:
                    pass
                
                # æ„å»ºè¯·æ±‚è´Ÿè½½
                payload = self._build_payload(base64_image, img_type)
                
                # å‘é€å¼‚æ­¥è¯·æ±‚
                async with session.post(
                    self.api_endpoint,
                    headers=self.headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=self.timeout)
                ) as response:
                    
                    if response.status != 200:
                        error_text = await response.text()
                        error_msg = f"APIé”™è¯¯ ({response.status})"
                        
                        try:
                            error_data = await response.json()
                            error_msg += f": {error_data.get('message', 'æœªçŸ¥é”™è¯¯')}"
                        except:
                            error_msg += f": {error_text[:200]}"
                        
                        return {
                            "error": "API_ERROR",
                            "message": error_msg,
                            "status_code": response.status
                        }
                    
                    # è§£æå“åº”
                    response_data = await response.json()
                    
                    # Ensure usage data is robust before it's used or saved
                    usage_data = response_data.get("usage", {})
                    usage_data.setdefault('prompt_tokens', 0)
                    usage_data.setdefault('completion_tokens', 0)
                    usage_data.setdefault('total_tokens', usage_data.get('prompt_tokens', 0) + usage_data.get('completion_tokens', 0))
                    response_data['usage'] = usage_data

                    if "choices" not in response_data or len(response_data["choices"]) == 0:
                        return {
                            "error": "NO_RESPONSE",
                            "message": "APIè¿”å›äº†ç©ºå“åº”"
                        }
                    
                    content = response_data["choices"][0]["message"]["content"]
                    
                    # æå–XMLç»“æœ
                    result = self._extract_xml(content)
                    
                    # æ·»åŠ å…ƒæ•°æ®
                    if isinstance(result, dict) and "error" not in result:
                        result["api_usage"] = response_data.get("usage", {})
                        result["api_provider"] = "volces"
                    
                    return result
                    
            except asyncio.TimeoutError:
                return {
                    "error": "TIMEOUT_ERROR",
                    "message": f"è¯·æ±‚è¶…æ—¶ (è¶…è¿‡ {self.timeout} ç§’)"
                }
            except aiohttp.ClientError as e:
                return {
                    "error": "CONNECTION_ERROR",
                    "message": f"ç½‘ç»œè¿æ¥å¤±è´¥: {str(e)}"
                }
            except Exception as e:
                return {
                    "error": "EXCEPTION",
                    "message": str(e),
                    "traceback": traceback.format_exc()
                }

def find_images(root_dir, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.webp')):
    """é€’å½’æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶"""
    all_images = []
    for ext in extensions:
        all_images.extend(glob.glob(os.path.join(root_dir, '**', f'*{ext}'), recursive=True))
        all_images.extend(glob.glob(os.path.join(root_dir, '**', f'*{ext.upper()}'), recursive=True))
    return sorted(list(set(all_images)))  # å»é‡å¹¶æ’åº

async def process_single_image(analyzer, session, img_path, force_rerun, debug_mode, cost_calculator):
    """å¤„ç†å•ä¸ªå›¾ç‰‡çš„å¼‚æ­¥å‡½æ•°ï¼ˆå¢åŠ æˆæœ¬ç»Ÿè®¡ï¼‰"""
    json_path = os.path.splitext(img_path)[0] + '.json'
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°å¤„ç†
    if os.path.exists(json_path) and not force_rerun:
        return {"status": "skipped", "path": img_path}
    
    # åˆ†æå›¾ç‰‡
    result = await analyzer.analyze_image(session, img_path)
    
    if result and "error" not in result:
        try:
            # ç»Ÿè®¡APIä½¿ç”¨æˆæœ¬
            if "api_usage" in result:
                cost_calculator.add_usage(result["api_usage"])
            
            # å¼‚æ­¥ä¿å­˜ç»“æœ
            os.makedirs(os.path.dirname(json_path), exist_ok=True)
            async with aiofiles.open(json_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(result, ensure_ascii=False, indent=2))
            return {"status": "success", "path": img_path, "result": result}
        except Exception as e:
            return {
                "status": "save_error", 
                "path": img_path, 
                "error": str(e),
                "result": result
            }
    else:
        # å³ä½¿å¤±è´¥ä¹Ÿè¦ç»Ÿè®¡è¯·æ±‚æ•°
        cost_calculator.total_requests += 1
        return {
            "status": "analysis_error", 
            "path": img_path, 
            "error": result
        }

async def main():
    parser = argparse.ArgumentParser(description='å¼‚æ­¥æ‰¹é‡åˆ†æå›¾ç‰‡è´¨é‡')
    parser.add_argument('root_dir', type=str, help='åŒ…å«å›¾ç‰‡çš„æ ¹ç›®å½•')
    args = parser.parse_args()

    try:
        start_time = time.time()
        
        # åˆå§‹åŒ–åˆ†æå™¨å’Œæˆæœ¬è®¡ç®—å™¨
        analyzer = ImageQualityAnalyzer()
        cost_calculator = CostCalculator()
        
        # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡
        all_images = find_images(args.root_dir)
        
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        force_rerun = os.getenv('FORCE_RERUN', 'false').lower() == 'true'
        log_file = os.getenv('LOG_FILE', 'processing_errors.jsonl')
        debug_mode = os.getenv('DEBUG_MODE', 'false').lower() == 'true'

        # è¿‡æ»¤éœ€è¦å¤„ç†çš„ä»»åŠ¡
        tasks_to_process = []
        skipped_count = 0
        
        for img_path in all_images:
            json_path = os.path.splitext(img_path)[0] + '.json'
            if not os.path.exists(json_path) or force_rerun:
                tasks_to_process.append(img_path)
            else:
                skipped_count += 1

        # ç¾åŒ–çš„ç»Ÿè®¡ä¿¡æ¯è¾“å‡º
        print(f"\n{Fore.CYAN}ğŸ“Š å›¾ç‰‡å¤„ç†ç»Ÿè®¡:{Style.RESET_ALL}")
        print(f"  ğŸ“ æ‰«æç›®å½•: {Fore.YELLOW}{args.root_dir}{Style.RESET_ALL}")
        print(f"  ğŸ–¼ï¸  å‘ç°å›¾ç‰‡: {Fore.GREEN}{len(all_images)}{Style.RESET_ALL} å¼ ")
        print(f"  â­ï¸  å·²å¤„ç†: {Fore.BLUE}{skipped_count}{Style.RESET_ALL} å¼  (è·³è¿‡)")
        print(f"  ğŸ”„ å¾…å¤„ç†: {Fore.MAGENTA}{len(tasks_to_process)}{Style.RESET_ALL} å¼ ")
        
        if len(tasks_to_process) == 0:
            print(f"\n{Fore.GREEN}âœ… æ‰€æœ‰å›¾ç‰‡éƒ½å·²å¤„ç†å®Œæˆï¼{Style.RESET_ALL}")
            return 0
        
        print(f"\n{Fore.YELLOW}ğŸš€ å¼€å§‹å¼‚æ­¥å¤„ç†...{Style.RESET_ALL}")
        
        # åˆ›å»ºå¼‚æ­¥HTTPä¼šè¯
        connector = aiohttp.TCPConnector(limit=50, limit_per_host=10)
        timeout = aiohttp.ClientTimeout(total=300)
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            # åˆ›å»ºæ‰€æœ‰å¤„ç†ä»»åŠ¡
            processing_tasks = [
                process_single_image(analyzer, session, img_path, force_rerun, debug_mode, cost_calculator)
                for img_path in tasks_to_process
            ]
            
            # å¼‚æ­¥æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼Œå¸¦è¿›åº¦æ¡
            results = []
            
            # ä½¿ç”¨tqdmçš„å¼‚æ­¥è¿›åº¦æ¡åŒ…è£…asyncio.as_completed
            with tqdm(total=len(processing_tasks), desc=f"{Fore.GREEN}å¤„ç†è¿›åº¦{Style.RESET_ALL}") as pbar:
                for coro in asyncio.as_completed(processing_tasks):
                    result = await coro
                    results.append(result)
                    pbar.update(1)
                    
                    # å®æ—¶æ˜¾ç¤ºå¤„ç†çŠ¶æ€
                    if result["status"] == "success":
                        pbar.set_postfix_str(f"{Fore.GREEN}âœ“{Style.RESET_ALL} {os.path.basename(result['path'])}")
                    elif result["status"] == "analysis_error":
                        pbar.set_postfix_str(f"{Fore.RED}âœ—{Style.RESET_ALL} {os.path.basename(result['path'])}")
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r["status"] == "success")
        skipped_count_new = sum(1 for r in results if r["status"] == "skipped")
        error_count = len(results) - success_count - skipped_count_new
        
        # å¤„ç†é”™è¯¯æ—¥å¿—
        error_log = []
        for result in results:
            if result["status"] in ["analysis_error", "save_error"]:
                img_path = result["path"]
                if result["status"] == "analysis_error":
                    error_info = result["error"]
                    error_entry = {
                        "file": img_path,
                        "error_type": error_info.get("error", "UNKNOWN_ERROR"),
                        "message": error_info.get("message", "æœªçŸ¥é”™è¯¯"),
                        "raw_output": error_info.get("raw_output", ""),
                        "traceback": error_info.get("traceback", ""),
                        "status_code": error_info.get("status_code", "")
                    }
                else:  # save_error
                    error_entry = {
                        "file": img_path,
                        "error_type": "SAVE_ERROR",
                        "message": result["error"],
                        "analysis_result": result.get("result", {})
                    }
                
                error_log.append(error_entry)
                
                # å®æ—¶æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                print(f"\n{Fore.RED}âŒ å¤„ç†å¤±è´¥{Style.RESET_ALL} {os.path.basename(img_path)}:")
                print(f"   {Fore.YELLOW}é”™è¯¯ç±»å‹:{Style.RESET_ALL} {error_entry.get('error_type', 'UNKNOWN')}")
                print(f"   {Fore.YELLOW}é”™è¯¯ä¿¡æ¯:{Style.RESET_ALL} {error_entry.get('message', 'æœªçŸ¥é”™è¯¯')}")
                
                if debug_mode and error_entry.get('raw_output'):
                    print(f"   {Fore.CYAN}åŸå§‹è¾“å‡º:{Style.RESET_ALL} {error_entry['raw_output'][:100]}...")
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        end_time = time.time()
        processing_time = end_time - start_time
        
        # æœ€ç»ˆç»Ÿè®¡è¾“å‡º
        print(f"\n{Fore.GREEN}ğŸ‰ å¤„ç†å®Œæˆï¼{Style.RESET_ALL}")
        print(f"  âœ… æˆåŠŸ: {Fore.GREEN}{success_count}{Style.RESET_ALL}/{len(tasks_to_process)}")
        print(f"  âŒ å¤±è´¥: {Fore.RED}{error_count}{Style.RESET_ALL}")
        print(f"  â±ï¸  è€—æ—¶: {Fore.BLUE}{processing_time:.1f}{Style.RESET_ALL} ç§’")
        print(f"  ğŸš€ å¹³å‡é€Ÿåº¦: {Fore.MAGENTA}{len(tasks_to_process)/processing_time:.1f}{Style.RESET_ALL} å¼ /ç§’")
        
        # æ˜¾ç¤ºæˆæœ¬æŠ¥å‘Š
        cost_report, cost_data = cost_calculator.format_cost_report(processing_time, success_count)
        print(cost_report)
        
        # ä¿å­˜é”™è¯¯æ—¥å¿—
        if error_log:
            async with aiofiles.open(log_file, 'w', encoding='utf-8') as f:
                for entry in error_log:
                    await f.write(json.dumps(entry, ensure_ascii=False) + '\n')
            print(f"  ğŸ“ é”™è¯¯æ—¥å¿—: {Fore.YELLOW}{log_file}{Style.RESET_ALL}")
        
        # å¯é€‰ï¼šä¿å­˜æˆæœ¬æŠ¥å‘Šåˆ°æ–‡ä»¶
        cost_report_file = os.getenv('COST_REPORT_FILE', 'cost_report.json')
        if os.getenv('SAVE_COST_REPORT', 'false').lower() == 'true':
            async with aiofiles.open(cost_report_file, 'w', encoding='utf-8') as f:
                cost_data['processing_time'] = processing_time
                cost_data['processed_images'] = success_count
                cost_data['timestamp'] = time.strftime('%Y-%m-%d %H:%M:%S')
                await f.write(json.dumps(cost_data, ensure_ascii=False, indent=2))
            print(f"  ğŸ’° æˆæœ¬æŠ¥å‘Š: {Fore.YELLOW}{cost_report_file}{Style.RESET_ALL}")
                    
    except ValueError as e:
        print(f"{Fore.RED}âŒ é…ç½®é”™è¯¯:{Style.RESET_ALL} {e}")
        print("è¯·ç¡®ä¿ .env æ–‡ä»¶å­˜åœ¨å¹¶åŒ…å«æ‰€æœ‰å¿…éœ€çš„é…ç½®é¡¹ã€‚")
        return 1
    except Exception as e:
        print(f"{Fore.RED}âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥:{Style.RESET_ALL} {e}")
        if os.getenv('DEBUG_MODE', 'false').lower() == 'true':
            print(traceback.format_exc())
        return 1
        
    return 0

if __name__ == "__main__":
    exit(asyncio.run(main()))